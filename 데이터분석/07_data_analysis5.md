# ðŸŽ¯ ì˜¤ëŠ˜ í•™ìŠµí•œ í•µì‹¬ ë‚´ìš© TIL

# EDA ì‹¬í™” ê°•ì˜ ë…¸íŠ¸ ðŸ“Š

## ðŸŽ¯ ì „ì²´ í•™ìŠµ ëª©í‘œ
Python, NumPy, Pandas ê¸°ì´ˆë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì ìš©í•  ìˆ˜ ìžˆëŠ” ê³ ê¸‰ EDA ê¸°ë²•**ì„ ìŠµë“í•˜ì—¬, ë°ì´í„°ì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë°œêµ´í•˜ëŠ” ëŠ¥ë ¥ í–¥ìƒ

***

## ðŸ“– 1êµì‹œ: EDA ë°©ë²•ë¡ ê³¼ ì „ëžµ
> *"ì²´ê³„ì  ì ‘ê·¼ìœ¼ë¡œ íš¨ìœ¨ì  ì¸ì‚¬ì´íŠ¸ ë°œê²¬"*

### ðŸ”‘ í•µì‹¬ ê°œë…
- **EDAì˜ 3ë‹¨ê³„ ì—¬ì •**: ê´€ì°°(Observation) â†’ íƒìƒ‰(Exploration) â†’ í†µì°°(Insight)
- **80-20 ë²•ì¹™**: í•µì‹¬ 20% ë³€ìˆ˜ì— ì§‘ì¤‘í•˜ì—¬ 80% ì¸ì‚¬ì´íŠ¸ í™•ë³´
- **ê°€ì„¤ ì¤‘ì‹¬ íƒìƒ‰**: ë¬´ìž‘ì • ë¶„ì„ë³´ë‹¤ëŠ” "ë§Œì•½ ~ë¼ë©´, ~ê°€ ê´€ì°°ë  ê²ƒì´ë‹¤" ê°€ì„¤ ì„¤ì •

### ðŸ’¡ ì‹¤ìŠµ ë°ì´í„°: íƒ€ì´íƒ€ë‹‰ ìƒì¡´ ìš”ì¸ ë¶„ì„
**ì£¼ìš” ë°œê²¬ ì‚¬í•­:**
- 1ë“±ê¸‰ ì—¬ì„± 100% ìƒì¡´ â†’ ê³„ê¸‰ë³„ ì°¨ë³„ì  êµ¬ì¡° í™•ì¸
- ì •ì±… ì œì•ˆ: ê³µí‰í•œ êµ¬ì¡° ì‹œìŠ¤í…œ êµ¬ì¶•

### ðŸ“‹ EDA ì „ëžµ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ë°ì´í„° ê°œìš” íŒŒì•… (shape, dtypes, info)
- [ ] ê²°ì¸¡ê°’ íŒ¨í„´ ë¶„ì„
- [ ] ê¸°ìˆ í†µê³„ ìš”ì•½
- [ ] ë¶„í¬ ì‹œê°í™”
- [ ] ë³€ìˆ˜ ê°„ ê´€ê³„ íƒìƒ‰
- [ ] ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì„¤ ê²€ì¦

***

## ðŸ” 2êµì‹œ: ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨ê³¼ í”„ë¡œíŒŒì¼ë§
> *"ìžë™í™”ëœ í’ˆì§ˆ ì§„ë‹¨ + ë„ë©”ì¸ ì§€ì‹ = ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ë°ì´í„°"*

### ðŸ”‘ í•µì‹¬ ê°œë…
- **ë°ì´í„° í’ˆì§ˆì˜ 6ì°¨ì›**: ì™„ì „ì„±, ì •í™•ì„±, ì¼ê´€ì„±, ìœ íš¨ì„±, ì ì‹œì„±, ìœ ì¼ì„±
- **ìžë™í™”ëœ í”„ë¡œíŒŒì¼ë§**: ë°˜ë³µì  í’ˆì§ˆ ê²€ì‚¬ì˜ í•¨ìˆ˜í™”ë¡œ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
- **ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦**: í†µê³„ì  ì •ìƒì„±ì„ ë„˜ì–´ì„  ë„ë©”ì¸ ë…¼ë¦¬ í™•ì¸

### ðŸ’¡ ì‹¤ìŠµ ë°ì´í„°: Boston Housing í’ˆì§ˆ ì§„ë‹¨

**ìžë™í™” í”„ë¡œíŒŒì¼ë§ í•¨ìˆ˜:**
```python
def data_profile_report(df):
    """ìžë™í™”ëœ ë°ì´í„° í”„ë¡œíŒŒì¼ë§"""
    return {
        'shape': df.shape,
        'missing_percent': df.isnull().sum() / len(df) * 100,
        'dtypes': df.dtypes,
        'duplicates': df.duplicated().sum()
    }
```

### ðŸ“Š í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
```python
def calculate_quality_score(df):
    """ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
    completeness = (1 - df.isnull().sum().sum() / df.size) * 100
    uniqueness = (1 - df.duplicated().sum() / len(df)) * 100
    return (completeness + uniqueness) / 2
```

### ðŸ› ï¸ ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦ ì˜ˆì‹œ
- ì£¼íƒ ê°€ê²© > 0
- ë°© ê°œìˆ˜ >= 1
- ì—°ì‹ê³¼ í˜„ìž¬ ë‚ ì§œ ë…¼ë¦¬ì  ì¼ê´€ì„±

***

## ðŸŽ¯ 3êµì‹œ: ê³ ê¸‰ ê²°ì¸¡ê°’ê³¼ ì´ìƒê°’ ì²˜ë¦¬
> *"ê²°ì¸¡ê°’ê³¼ ì´ìƒê°’ì€ ì œê±°í•  ë¬¸ì œê°€ ì•„ë‹ˆë¼ í•´ì„í•  ì •ë³´"*

### ðŸ”‘ í•µì‹¬ ê°œë…
- **ê²°ì¸¡ ë©”ì»¤ë‹ˆì¦˜**: MCAR(ì™„ì „ë¬´ìž‘ìœ„) / MAR(ì¡°ê±´ë¶€ë¬´ìž‘ìœ„) / MNAR(ë¹„ë¬´ìž‘ìœ„)
- **ê³ ê¸‰ ëŒ€ì²´ ê¸°ë²•**: KNN, MICEë¡œ ë³€ìˆ˜ ê°„ ê´€ê³„ ë³´ì¡´
- **ë‹¤ë³€ëŸ‰ ì´ìƒê°’ íƒì§€**: ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬, Isolation Forest ì¡°í•©
- **ë¹„ì¦ˆë‹ˆìŠ¤ ì¤‘ì‹¬ í•´ì„**: í†µê³„ì  ì´ìƒê°’ì„ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒë¡œ ì „í™˜

### ðŸ’¡ ì‹¤ìŠµ ë°ì´í„°: ì „ìžìƒê±°ëž˜ ê³ ê° ë°ì´í„°

### ðŸ“Š ê²°ì¸¡ê°’ ì²˜ë¦¬ ë¹„êµ

| ë°©ë²• | ìž¥ì  | ë‹¨ì  | ì ìš©ìƒí™© |
|------|------|------|----------|
| **í‰ê·  ëŒ€ì²´** | ë¹ ë¦„, ë‹¨ìˆœ | ë¶„ì‚° ì¶•ì†Œ | ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ |
| **KNN ëŒ€ì²´** | êµ­ì†ŒíŒ¨í„´ ë³´ì¡´ | ê³„ì‚°ë¹„ìš© ë†’ìŒ | ì¤‘ê°„ ê·œëª¨ ë°ì´í„° |
| **MICE ëŒ€ì²´** | ê´€ê³„ ìµœëŒ€ ë³´ì¡´ | ì‹œê°„ ì†Œìš” | ì •ë°€ ë¶„ì„ í•„ìš”ì‹œ |

### ðŸŽ¯ ì´ìƒê°’ íƒì§€ íŒŒì´í”„ë¼ì¸
```python
def outlier_detection_pipeline(df):
    """ë‹¤ë³€ëŸ‰ ì´ìƒê°’ íƒì§€"""
    # 1. ë‹¨ë³€ëŸ‰: IQR ë°©ë²•
    # 2. ë‹¤ë³€ëŸ‰: ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬
    # 3. ML ê¸°ë°˜: Isolation Forest
    # 4. ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„
    pass
```

### ðŸ› ï¸ ì‹¤ì œ ì´ìƒê°’ ì²˜ë¦¬ ì „ëžµ
1. **íƒì§€** â†’ í†µê³„ì /ML ê¸°ë²• ì¡°í•©
2. **ë¶„ë¥˜** â†’ ì˜¤ë¥˜ vs ê·¹ê°’ vs íŠ¹ì´ì‚¬ë¡€
3. **ì²˜ë¦¬** â†’ ì œê±°/ë³€í™˜/ë³„ë„ë¶„ì„
4. **ê²€ì¦** â†’ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì  í•´ì„

***

## ðŸŽ“ í†µí•© í•™ìŠµ ì„±ê³¼

### âœ… ê¸°ìˆ ì  ì—­ëŸ‰ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ì²´ê³„ì  EDA ì „ëžµ ìˆ˜ë¦½ ë° ì‹¤í–‰
- [ ] ìžë™í™”ëœ ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨ ì‹œìŠ¤í…œ êµ¬ì¶•
- [ ] ê²°ì¸¡ ë©”ì»¤ë‹ˆì¦˜ ì§„ë‹¨ ë° ì ì ˆí•œ ì²˜ë¦¬ ë°©ë²• ì„ íƒ
- [ ] ë‹¤ë³€ëŸ‰ ì´ìƒê°’ íƒì§€ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì  í•´ì„
- [ ] ì‹¤ì œ ë°ì´í„° ë³€í™˜ ë° ì‚¬í›„ ì˜í–¥ ë¶„ì„

### ðŸš€ ì‹¤ë¬´ ì ìš© í•µì‹¬ í¬ì¸íŠ¸

**1êµì‹œ í•µì‹¬:**
- ê°€ì„¤ ì¤‘ì‹¬ íƒìƒ‰ìœ¼ë¡œ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
- 80-20 ë²•ì¹™ìœ¼ë¡œ í•µì‹¬ ë³€ìˆ˜ ì§‘ì¤‘

**2êµì‹œ í•µì‹¬:**
- ìžë™í™”ëœ í’ˆì§ˆ ì§„ë‹¨ìœ¼ë¡œ ì‹ ë¢°ì„± í™•ë³´
- ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦ìœ¼ë¡œ ì‹¤ë¬´ ì ìš©ì„± í–¥ìƒ

**3êµì‹œ í•µì‹¬:**
- ê²°ì¸¡ê°’/ì´ìƒê°’ì„ ì •ë³´ë¡œ í™œìš©
- ë‹¤ë³€ëŸ‰ ì ‘ê·¼ìœ¼ë¡œ ìˆ¨ê²¨ì§„ íŒ¨í„´ ë°œê²¬

***

## ðŸ“ˆ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ ì°½ì¶œ ì‚¬ë¡€

### ðŸš¢ íƒ€ì´íƒ€ë‹‰ ë¶„ì„ â†’ ì•ˆì „ ì •ì±…
- 1ë“±ê¸‰ ì—¬ì„± 100% ìƒì¡´ â†’ ê³„ê¸‰ë³„ ì°¨ë³„ì  êµ¬ì¡° í™•ì¸
- **ì •ì±… ì œì•ˆ**: ê³µí‰í•œ êµ¬ì¡° ì‹œìŠ¤í…œ êµ¬ì¶•

### ðŸ  Boston Housing â†’ ê°€ê²© ì˜ˆì¸¡
- ì™„ë²½í•œ ë°ì´í„° í’ˆì§ˆ í™•ì¸ â†’ ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ëª¨ë¸ ê¸°ë°˜ ë§ˆë ¨
- LSTAT(í•˜ìœ„ê³„ì¸µ ë¹„ìœ¨)ì™€ ê°€ê²©ì˜ ê°•í•œ ìŒì˜ ìƒê´€ê´€ê³„ í™•ì¸

### ðŸ›’ ì „ìžìƒê±°ëž˜ â†’ ê³ ê° ê´€ë¦¬
- VIP ê³ ê° 5ëª… ì‹ë³„ â†’ ê°œì¸í™” ì„œë¹„ìŠ¤ ì „ëžµ
- íœ´ë©´ ê³ ê° ë¶„ë¥˜ â†’ ìž¬í™œì„±í™” ìº íŽ˜ì¸ íƒ€ê²ŸíŒ…
- ë°ì´í„° ì˜¤ë¥˜ ìˆ˜ì • â†’ ë¶„ì„ ì‹ ë¢°ì„± í–¥ìƒ

***

## ðŸŽ¯ ë‹¤ìŒ ë‹¨ê³„ í•™ìŠµ ë¡œë“œë§µ

### ðŸ“š ê¶Œìž¥ ì‹¬í™” í•™ìŠµ (4-12êµì‹œ)
- **ë¶„í¬ ë¶„ì„ê³¼ ë³€í™˜ ê¸°ë²•** - ì •ê·œì„± ê²€ì •, ê³ ê¸‰ ë³€í™˜
- **ìƒê´€ê´€ê³„ ì‹¬í™” ë¶„ì„** â­ - ë¹„ì„ í˜•, íŽ¸ìƒê´€, ì¸ê³¼ì¶”ë¡ 
- **ë²”ì£¼í˜• ë°ì´í„° ê³ ê¸‰ ë¶„ì„** - ê³ ì°¨ì› ì²˜ë¦¬, ì—°ê´€ì„± ì¸¡ì •
- **ì°¨ì›ì¶•ì†Œì™€ íŠ¹ì„±ì„ íƒ** - PCA ì‹¬í™”, t-SNE, UMAP

### ðŸ› ï¸ ì‹¤ë¬´ í”„ë¡œì íŠ¸ ì œì•ˆ
- **ì´ˆê¸‰**: Kaggle ë°ì´í„°ë¡œ ì „ì²´ EDA íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- **ì¤‘ê¸‰**: ì‹¤ì œ ì—…ë¬´ ë°ì´í„°ë¡œ í’ˆì§ˆ ì§„ë‹¨ ì‹œìŠ¤í…œ ê°œë°œ
- **ê³ ê¸‰**: ìžë™í™”ëœ EDA ë³´ê³ ì„œ ìƒì„± ì‹œìŠ¤í…œ êµ¬ì¶•

***

## ðŸ’¡ ìµœì¢… í•µì‹¬ ë©”ì‹œì§€

> **"ë°ì´í„° ë¶„ì„ì˜ 80%ëŠ” EDAì—ì„œ ê²°ì •ë©ë‹ˆë‹¤"**

### 3êµì‹œë¥¼ í†µí•´ ë‹¬ì„±í•œ ê²ƒ:
âœ… ë¬´ìž‘ì • ë¶„ì„ â†’ **ì „ëžµì  ì ‘ê·¼**  
âœ… ë‹¨ìˆœ í†µê³„ â†’ **ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸**  
âœ… ì´ìƒê°’ ì œê±° â†’ **ê°€ì¹˜ ìžˆëŠ” í•´ì„**  
âœ… ì¼íšŒì„± ë¶„ì„ â†’ **ìž¬ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œìŠ¤í…œ**

***

## ðŸ“± í€µ ë ˆí¼ëŸ°ìŠ¤ ì½”ë“œ

```python
# ê¸°ë³¸ EDA íŒŒì´í”„ë¼ì¸
def quick_eda(df):
    print("ðŸ“Š ë°ì´í„° ê°œìš”")
    print(f"Shape: {df.shape}")
    print(f"ê²°ì¸¡ê°’: {df.isnull().sum().sum()}")
    print(f"ì¤‘ë³µê°’: {df.duplicated().sum()}")
    
    print("\nðŸ“ˆ ê¸°ìˆ í†µê³„")
    display(df.describe())
    
    print("\nðŸ” ë°ì´í„° íƒ€ìž…")
    print(df.dtypes.value_counts())

# í’ˆì§ˆ ì§„ë‹¨
def quality_check(df):
    quality_score = calculate_quality_score(df)
    print(f"ë°ì´í„° í’ˆì§ˆ ì ìˆ˜: {quality_score:.2f}%")
    return quality_score > 80

# ê²°ì¸¡ê°’ ì²˜ë¦¬
from sklearn.impute import KNNImputer
def advanced_imputation(df, method='knn'):
    if method == 'knn':
        imputer = KNNImputer(n_neighbors=5)
        return pd.DataFrame(imputer.fit_transform(df), columns=df.columns)
```

[1] https://learn.dailyalgo.kr/courses/ai-%EA%B8%B0%EB%B0%98-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D%EA%B0%80-%EC%96%91%EC%84%B1-%EA%B3%BC%EC%A0%95/23f611ac-3a00-8083-8b18-d20722c9baec