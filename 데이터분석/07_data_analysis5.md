# 🎯 오늘 학습한 핵심 내용 TIL

# EDA 심화 강의 노트 📊

## 🎯 전체 학습 목표
Python, NumPy, Pandas 기초를 바탕으로 **실무에서 바로 적용할 수 있는 고급 EDA 기법**을 습득하여, 데이터에서 비즈니스 인사이트를 효과적으로 발굴하는 능력 향상

***

## 📖 1교시: EDA 방법론과 전략
> *"체계적 접근으로 효율적 인사이트 발견"*

### 🔑 핵심 개념
- **EDA의 3단계 여정**: 관찰(Observation) → 탐색(Exploration) → 통찰(Insight)
- **80-20 법칙**: 핵심 20% 변수에 집중하여 80% 인사이트 확보
- **가설 중심 탐색**: 무작정 분석보다는 "만약 ~라면, ~가 관찰될 것이다" 가설 설정

### 💡 실습 데이터: 타이타닉 생존 요인 분석
**주요 발견 사항:**
- 1등급 여성 100% 생존 → 계급별 차별적 구조 확인
- 정책 제안: 공평한 구조 시스템 구축

### 📋 EDA 전략 체크리스트
- [ ] 데이터 개요 파악 (shape, dtypes, info)
- [ ] 결측값 패턴 분석
- [ ] 기술통계 요약
- [ ] 분포 시각화
- [ ] 변수 간 관계 탐색
- [ ] 비즈니스 가설 검증

***

## 🔍 2교시: 데이터 품질 진단과 프로파일링
> *"자동화된 품질 진단 + 도메인 지식 = 신뢰할 수 있는 데이터"*

### 🔑 핵심 개념
- **데이터 품질의 6차원**: 완전성, 정확성, 일관성, 유효성, 적시성, 유일성
- **자동화된 프로파일링**: 반복적 품질 검사의 함수화로 효율성 극대화
- **비즈니스 규칙 검증**: 통계적 정상성을 넘어선 도메인 논리 확인

### 💡 실습 데이터: Boston Housing 품질 진단

**자동화 프로파일링 함수:**
```python
def data_profile_report(df):
    """자동화된 데이터 프로파일링"""
    return {
        'shape': df.shape,
        'missing_percent': df.isnull().sum() / len(df) * 100,
        'dtypes': df.dtypes,
        'duplicates': df.duplicated().sum()
    }
```

### 📊 품질 점수 계산
```python
def calculate_quality_score(df):
    """데이터 품질 점수 계산"""
    completeness = (1 - df.isnull().sum().sum() / df.size) * 100
    uniqueness = (1 - df.duplicated().sum() / len(df)) * 100
    return (completeness + uniqueness) / 2
```

### 🛠️ 비즈니스 규칙 검증 예시
- 주택 가격 > 0
- 방 개수 >= 1
- 연식과 현재 날짜 논리적 일관성

***

## 🎯 3교시: 고급 결측값과 이상값 처리
> *"결측값과 이상값은 제거할 문제가 아니라 해석할 정보"*

### 🔑 핵심 개념
- **결측 메커니즘**: MCAR(완전무작위) / MAR(조건부무작위) / MNAR(비무작위)
- **고급 대체 기법**: KNN, MICE로 변수 간 관계 보존
- **다변량 이상값 탐지**: 마할라노비스 거리, Isolation Forest 조합
- **비즈니스 중심 해석**: 통계적 이상값을 비즈니스 기회로 전환

### 💡 실습 데이터: 전자상거래 고객 데이터

### 📊 결측값 처리 비교

| 방법 | 장점 | 단점 | 적용상황 |
|------|------|------|----------|
| **평균 대체** | 빠름, 단순 | 분산 축소 | 빠른 프로토타이핑 |
| **KNN 대체** | 국소패턴 보존 | 계산비용 높음 | 중간 규모 데이터 |
| **MICE 대체** | 관계 최대 보존 | 시간 소요 | 정밀 분석 필요시 |

### 🎯 이상값 탐지 파이프라인
```python
def outlier_detection_pipeline(df):
    """다변량 이상값 탐지"""
    # 1. 단변량: IQR 방법
    # 2. 다변량: 마할라노비스 거리
    # 3. ML 기반: Isolation Forest
    # 4. 비즈니스 해석
    pass
```

### 🛠️ 실제 이상값 처리 전략
1. **탐지** → 통계적/ML 기법 조합
2. **분류** → 오류 vs 극값 vs 특이사례
3. **처리** → 제거/변환/별도분석
4. **검증** → 비즈니스 관점 해석

***

## 🎓 통합 학습 성과

### ✅ 기술적 역량 체크리스트
- [ ] 체계적 EDA 전략 수립 및 실행
- [ ] 자동화된 데이터 품질 진단 시스템 구축
- [ ] 결측 메커니즘 진단 및 적절한 처리 방법 선택
- [ ] 다변량 이상값 탐지 및 비즈니스 관점 해석
- [ ] 실제 데이터 변환 및 사후 영향 분석

### 🚀 실무 적용 핵심 포인트

**1교시 핵심:**
- 가설 중심 탐색으로 효율성 극대화
- 80-20 법칙으로 핵심 변수 집중

**2교시 핵심:**
- 자동화된 품질 진단으로 신뢰성 확보
- 비즈니스 규칙 검증으로 실무 적용성 향상

**3교시 핵심:**
- 결측값/이상값을 정보로 활용
- 다변량 접근으로 숨겨진 패턴 발견

***

## 📈 비즈니스 가치 창출 사례

### 🚢 타이타닉 분석 → 안전 정책
- 1등급 여성 100% 생존 → 계급별 차별적 구조 확인
- **정책 제안**: 공평한 구조 시스템 구축

### 🏠 Boston Housing → 가격 예측
- 완벽한 데이터 품질 확인 → 신뢰할 수 있는 모델 기반 마련
- LSTAT(하위계층 비율)와 가격의 강한 음의 상관관계 확인

### 🛒 전자상거래 → 고객 관리
- VIP 고객 5명 식별 → 개인화 서비스 전략
- 휴면 고객 분류 → 재활성화 캠페인 타겟팅
- 데이터 오류 수정 → 분석 신뢰성 향상

***

## 🎯 다음 단계 학습 로드맵

### 📚 권장 심화 학습 (4-12교시)
- **분포 분석과 변환 기법** - 정규성 검정, 고급 변환
- **상관관계 심화 분석** ⭐ - 비선형, 편상관, 인과추론
- **범주형 데이터 고급 분석** - 고차원 처리, 연관성 측정
- **차원축소와 특성선택** - PCA 심화, t-SNE, UMAP

### 🛠️ 실무 프로젝트 제안
- **초급**: Kaggle 데이터로 전체 EDA 파이프라인 구축
- **중급**: 실제 업무 데이터로 품질 진단 시스템 개발
- **고급**: 자동화된 EDA 보고서 생성 시스템 구축

***

## 💡 최종 핵심 메시지

> **"데이터 분석의 80%는 EDA에서 결정됩니다"**

### 3교시를 통해 달성한 것:
✅ 무작정 분석 → **전략적 접근**  
✅ 단순 통계 → **비즈니스 인사이트**  
✅ 이상값 제거 → **가치 있는 해석**  
✅ 일회성 분석 → **재사용 가능한 시스템**

***

## 📱 퀵 레퍼런스 코드

```python
# 기본 EDA 파이프라인
def quick_eda(df):
    print("📊 데이터 개요")
    print(f"Shape: {df.shape}")
    print(f"결측값: {df.isnull().sum().sum()}")
    print(f"중복값: {df.duplicated().sum()}")
    
    print("\n📈 기술통계")
    display(df.describe())
    
    print("\n🔍 데이터 타입")
    print(df.dtypes.value_counts())

# 품질 진단
def quality_check(df):
    quality_score = calculate_quality_score(df)
    print(f"데이터 품질 점수: {quality_score:.2f}%")
    return quality_score > 80

# 결측값 처리
from sklearn.impute import KNNImputer
def advanced_imputation(df, method='knn'):
    if method == 'knn':
        imputer = KNNImputer(n_neighbors=5)
        return pd.DataFrame(imputer.fit_transform(df), columns=df.columns)
```

[1] https://learn.dailyalgo.kr/courses/ai-%EA%B8%B0%EB%B0%98-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D%EA%B0%80-%EC%96%91%EC%84%B1-%EA%B3%BC%EC%A0%95/23f611ac-3a00-8083-8b18-d20722c9baec