{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6099343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 모듈 or 노트북 파일\n",
    "# 1. 회사 보고서 작성 에이전트 (RAG-약관)\n",
    "# 2. 학습 조교 에이전트 (RAG-수업자료)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import glob\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain import hub\n",
    "from pprint import pprint\n",
    "import os\n",
    "\n",
    "# 1. Load\n",
    "pdf_file_list = glob.glob(\"./mystudy/*.pdf\")  # mystudy 폴더 내 모든 pdf 파일 경로 리스트\n",
    "md_file_list = glob.glob(\"./mystudy/*.md\")    # 마크다운 파일들\n",
    "txt_file_list = glob.glob(\"./mystudy/*.txt\")  # 텍스트 파일들 [추가]\n",
    "all_docs = []\n",
    "\n",
    "# PDF 파일 로드\n",
    "for file_path in pdf_file_list:\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    # 각 문서에 파일 타입 메타데이터 추가\n",
    "    for doc in docs:\n",
    "        doc.metadata['file_type'] = 'pdf'\n",
    "        doc.metadata['source_file'] = os.path.basename(file_path)\n",
    "    all_docs.extend(docs)\n",
    "\n",
    "# 마크다운 파일 로드\n",
    "for file_path in md_file_list:\n",
    "    loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "    docs = loader.load()\n",
    "    # 각 문서에 파일 타입 메타데이터 추가\n",
    "    for doc in docs:\n",
    "        doc.metadata['file_type'] = 'markdown'\n",
    "        doc.metadata['source_file'] = os.path.basename(file_path)\n",
    "    all_docs.extend(docs)\n",
    "\n",
    "# 텍스트 파일 로드\n",
    "for file_path in txt_file_list:  # [추가]\n",
    "    loader = TextLoader(file_path, encoding=\"utf-8\")  # 필요 시 autodetect_encoding=True 사용 가능\n",
    "    docs = loader.load()\n",
    "    for doc in docs:\n",
    "        doc.metadata['file_type'] = 'text'\n",
    "        doc.metadata['source_file'] = os.path.basename(file_path)\n",
    "    all_docs.extend(docs)\n",
    "\n",
    "\n",
    "# 2. Split\n",
    "# 500글자당 1 청크 / 50글자는 겹치게 나눈다.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = text_splitter.split_documents(all_docs)\n",
    "\n",
    "print(\"분할 후 청크 수\", len(split_docs))\n",
    "\n",
    "\n",
    "# 3. 임베딩, 4. 벡터스토어 저장\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(documents=split_docs, embedding=embedding)\n",
    "\n",
    "# Test\n",
    "vectorstore.similarity_search(\"에이전트\", k=4)\n",
    "\n",
    "\n",
    "# 5. RAG\n",
    "# Prompt 세팅\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"당신은 제공된 자료를 기반으로 답변하는 전문 어시스턴트입니다.\n",
    "    \n",
    "주어진 문서 내용을 바탕으로 질문에 관련한 패턴을 발견하고 질문에 정확하고 상세하게 답변해주세요.\n",
    "문서에 정보가 없다면 \"제공된 자료에서 해당 정보를 찾을 수 없습니다\"라고 답하세요.\n",
    "\n",
    "문서 내용:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\"\"\"\n",
    ")\n",
    "\n",
    "# LLM 모델\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.7)\n",
    "\n",
    "# 검색기 생성(retriever 생성)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "pprint(chain.invoke(\"이 사람이 공부하고 배운 내용중 AI관련 스타트업 회사에서 채용시 참고할 부분이 있다면 정리하고 요약해줘\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
