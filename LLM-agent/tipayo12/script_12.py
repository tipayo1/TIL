# ì‚¬ìš© ì˜ˆì œ ì½”ë“œ ìƒì„±
usage_example_content = '''# usage_example.py - LangGraph RAG ì‹œìŠ¤í…œ ì‚¬ìš© ì˜ˆì œ
# RPG ê¸°ë°˜ ê²½ëŸ‰í™”ëœ Agentic AI ì‹œìŠ¤í…œ ë°ëª¨

import asyncio
import os
from typing import Dict, Any

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì˜ˆì œ
os.environ.setdefault("OPENAI_API_KEY", "your-openai-api-key")
os.environ.setdefault("PINECONE_API_KEY", "your-pinecone-api-key")  # ì„ íƒì‚¬í•­

from graph import GraphOrchestrator, GraphMode, run_rag_system
from db import create_database_manager_with_defaults
from utils import get_config, set_config

async def basic_usage_example():
    """ê¸°ë³¸ ì‚¬ìš© ì˜ˆì œ"""
    print("=== ê¸°ë³¸ RAG ì‹œìŠ¤í…œ ì‚¬ìš© ì˜ˆì œ ===")
    
    try:
        # 1. ê°„ë‹¨í•œ ì§ˆë‹µ
        result = await run_rag_system("ì•ˆë…•í•˜ì„¸ìš”, ë°˜ê°‘ìŠµë‹ˆë‹¤!", mode="standard")
        print(f"ë‹µë³€: {result.get('answer', '')}")
        print(f"ë‹µë³€ íƒ€ì…: {result.get('answer_type', '')}")
        
        # 2. HR ê´€ë ¨ ì§ˆë¬¸
        result = await run_rag_system("ì—°ì°¨ëŠ” ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?", mode="standard")
        print(f"\\nHR ì§ˆë¬¸ ë‹µë³€: {result.get('answer', '')}")
        
        # 3. ë³µì¡í•œ ë¶„ì„ ì‘ì—…
        result = await run_rag_system("ìš°ë¦¬ íšŒì‚¬ì˜ ì¸ì‚¬ ì •ì±…ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”", mode="rpg")
        print(f"\\nRPG ëª¨ë“œ ë‹µë³€: {result.get('answer', '')}")
        
    except Exception as e:
        print(f"ê¸°ë³¸ ì‚¬ìš© ì˜ˆì œ ì˜¤ë¥˜: {str(e)}")

async def advanced_usage_example():
    """ê³ ê¸‰ ì‚¬ìš© ì˜ˆì œ - ìˆ˜ë™ êµ¬ì„±"""
    print("\\n=== ê³ ê¸‰ ì‚¬ìš© ì˜ˆì œ - ìˆ˜ë™ êµ¬ì„± ===")
    
    try:
        # 1. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒì„± ë° ì´ˆê¸°í™”
        orchestrator = GraphOrchestrator()
        
        if not orchestrator.initialize_components():
            print("êµ¬ì„±ìš”ì†Œ ì´ˆê¸°í™” ì‹¤íŒ¨")
            return
        
        # 2. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
        if orchestrator.database_manager:
            # FAISS ë¡œì»¬ DB ì‚¬ìš© (Pineconeì´ ì—†ëŠ” ê²½ìš°)
            success = await orchestrator.database_manager.connect_database("faiss")
            if success:
                print("FAISS ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
            else:
                # ë©”ëª¨ë¦¬ DB í´ë°±
                success = await orchestrator.database_manager.connect_database("memory")
                print(f"ë©”ëª¨ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°: {success}")
        
        # 3. ë‹¤ì–‘í•œ ëª¨ë“œë¡œ ê·¸ë˜í”„ ë¹Œë“œ ë° ì‹¤í–‰
        modes_to_test = [
            ("standard", "í‘œì¤€ RAG ëª¨ë“œ"),
            ("rpg", "RPG ê°•í™” ëª¨ë“œ"),
            ("autonomous", "ììœ¨ ì—ì´ì „íŠ¸ ëª¨ë“œ"),
            ("coordinator", "ì¡°ì • ì—ì´ì „íŠ¸ ëª¨ë“œ")
        ]
        
        for mode_key, mode_name in modes_to_test:
            print(f"\\n--- {mode_name} í…ŒìŠ¤íŠ¸ ---")
            
            try:
                # ê·¸ë˜í”„ ë¹Œë“œ
                mode_enum = {
                    "standard": GraphMode.STANDARD,
                    "rpg": GraphMode.RPG_ENHANCED,
                    "autonomous": GraphMode.AUTONOMOUS,
                    "coordinator": GraphMode.COORDINATOR
                }[mode_key]
                
                orchestrator.build_graph(mode_enum)
                
                # ì‹¤í–‰
                result = await orchestrator.run("LangGraphì™€ RPGë¥¼ í™œìš©í•œ ì‹œìŠ¤í…œì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”")
                
                print(f"ì„±ê³µ: {result.get('success', False)}")
                print(f"ë‹µë³€: {result.get('answer', '')[:100]}...")
                
            except Exception as e:
                print(f"{mode_name} ì˜¤ë¥˜: {str(e)}")
        
    except Exception as e:
        print(f"ê³ ê¸‰ ì‚¬ìš© ì˜ˆì œ ì˜¤ë¥˜: {str(e)}")

async def document_loading_example():
    """ë¬¸ì„œ ë¡œë”© ë° ê²€ìƒ‰ ì˜ˆì œ"""
    print("\\n=== ë¬¸ì„œ ë¡œë”© ë° ê²€ìƒ‰ ì˜ˆì œ ===")
    
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì € ìƒì„±
        db_manager = create_database_manager_with_defaults()
        
        # ë¡œì»¬ ë©”ëª¨ë¦¬ DB ì—°ê²° (ë°ëª¨ìš©)
        success = await db_manager.connect_database("memory")
        if not success:
            print("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
            return
        
        # ìƒ˜í”Œ ë¬¸ì„œ ë°ì´í„° ìƒì„±
        from langchain_core.documents import Document
        sample_docs = [
            Document(
                page_content="LangGraphëŠ” ìƒíƒœ ê¸°ë°˜ ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì¶•í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.",
                metadata={"source": "langgraph_guide.md", "topic": "langgraph"}
            ),
            Document(
                page_content="Repository Planning Graph(RPG)ëŠ” ì½”ë“œ ìƒì„±ì„ ìœ„í•œ ê³„íš ê·¸ë˜í”„ ë°©ë²•ë¡ ì…ë‹ˆë‹¤.",
                metadata={"source": "rpg_paper.md", "topic": "rpg"}
            ),
            Document(
                page_content="Agentic AIëŠ” ììœ¨ì ì´ê³  ëª©í‘œ ì§€í–¥ì ì¸ AI ì‹œìŠ¤í…œì„ ì˜ë¯¸í•©ë‹ˆë‹¤.",
                metadata={"source": "agentic_ai.md", "topic": "agentic_ai"}
            )
        ]
        
        # ë¬¸ì„œ ì¶”ê°€
        success = await db_manager.add_documents_to_active_db(sample_docs)
        if success:
            print(f"ìƒ˜í”Œ ë¬¸ì„œ {len(sample_docs)}ê°œ ì¶”ê°€ ì™„ë£Œ")
        
        # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        queries = [
            "LangGraphë€ ë¬´ì—‡ì¸ê°€ìš”?",
            "RPGì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "Agentic AIì˜ íŠ¹ì§•ì€?"
        ]
        
        for query in queries:
            print(f"\\nê²€ìƒ‰ì–´: {query}")
            results = await db_manager.search_in_active_db(query, top_k=2)
            
            for i, doc in enumerate(results):
                print(f"  ê²°ê³¼ {i+1}: {doc.page_content[:50]}...")
                print(f"  ì¶œì²˜: {doc.metadata.get('source', 'unknown')}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ í†µê³„
        stats = await db_manager.get_database_stats()
        print(f"\\në°ì´í„°ë² ì´ìŠ¤ í†µê³„: {stats}")
        
    except Exception as e:
        print(f"ë¬¸ì„œ ë¡œë”© ì˜ˆì œ ì˜¤ë¥˜: {str(e)}")

async def configuration_example():
    """ì„¤ì • ê´€ë¦¬ ì˜ˆì œ"""
    print("\\n=== ì„¤ì • ê´€ë¦¬ ì˜ˆì œ ===")
    
    try:
        from utils import get_config, set_config, save_config
        
        # ê¸°ë³¸ ì„¤ì • ì¡°íšŒ
        llm_config = get_config("llm")
        print(f"LLM ì„¤ì •: {llm_config}")
        
        vector_db_config = get_config("vector_db")
        print(f"Vector DB ì„¤ì •: {vector_db_config}")
        
        # ì„¤ì • ë³€ê²½
        set_config("llm.temperature", 0.2)
        set_config("vector_db.chunk_size", 800)
        
        # ë„ë©”ì¸ë³„ ì„¤ì • ì¡°íšŒ
        hr_config = get_config("domains.hr", {})
        print(f"HR ë„ë©”ì¸ ì„¤ì •: {hr_config}")
        
        # ì„¤ì • ì €ì¥ (ì‹¤ì œë¡œëŠ” íŒŒì¼ì— ì €ì¥ë¨)
        # save_success = save_config()
        # print(f"ì„¤ì • ì €ì¥ ì„±ê³µ: {save_success}")
        
        print("ì„¤ì • ê´€ë¦¬ ì˜ˆì œ ì™„ë£Œ")
        
    except Exception as e:
        print(f"ì„¤ì • ê´€ë¦¬ ì˜ˆì œ ì˜¤ë¥˜: {str(e)}")

async def monitoring_example():
    """ëª¨ë‹ˆí„°ë§ ë° ì„±ëŠ¥ ë¶„ì„ ì˜ˆì œ"""
    print("\\n=== ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ===")
    
    try:
        from utils import record_execution, get_metrics, profile
        
        # ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ ì‚¬ìš©
        with profile("test_operation"):
            await asyncio.sleep(0.1)  # ê°€ìƒì˜ ì‘ì—…
            print("í”„ë¡œíŒŒì¼ë§ëœ ì‘ì—… ì™„ë£Œ")
        
        # ìˆ˜ë™ ì‹¤í–‰ ê¸°ë¡
        record_execution("test_component", "test_operation", 0.15, True, 
                        test_param="example_value")
        
        # ë©”íŠ¸ë¦­ ì¡°íšŒ
        metrics = get_metrics()
        print(f"\\ní˜„ì¬ ë©”íŠ¸ë¦­:")
        print(f"  ì´ ì‹¤í–‰ ìˆ˜: {metrics.get('total_executions', 0)}")
        print(f"  ì—…íƒ€ì„: {metrics.get('uptime', 0):.2f}ì´ˆ")
        
        component_metrics = metrics.get('component_metrics', {})
        for component, metric in component_metrics.items():
            print(f"  {component}: í‰ê·  {metric.get('avg_duration', 0):.3f}ì´ˆ, "
                  f"ì„±ê³µë¥  {metric.get('success_rate', 0):.1%}")
        
    except Exception as e:
        print(f"ëª¨ë‹ˆí„°ë§ ì˜ˆì œ ì˜¤ë¥˜: {str(e)}")

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ LangGraph RPG RAG ì‹œìŠ¤í…œ ì‚¬ìš© ì˜ˆì œ")
    print("=" * 50)
    
    try:
        # ê° ì˜ˆì œ ì‹¤í–‰
        await basic_usage_example()
        await advanced_usage_example()
        await document_loading_example()
        await configuration_example()
        await monitoring_example()
        
        print("\\nâœ… ëª¨ë“  ì˜ˆì œ ì‹¤í–‰ ì™„ë£Œ!")
        print("\\nğŸ“ ì°¸ê³ ì‚¬í•­:")
        print("- ì‹¤ì œ ì‚¬ìš©ì‹œ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”")
        print("- Pinecone ì‚¬ìš©ì‹œ PINECONE_API_KEYë„ ì„¤ì •í•˜ì„¸ìš”")
        print("- ë¬¸ì„œ íŒŒì¼ë“¤ì„ data/ í´ë”ì— ì¤€ë¹„í•˜ì„¸ìš”")
        print("- ìì„¸í•œ ì„¤ì •ì€ config.yaml íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”")
        
    except Exception as e:
        print(f"\\nâŒ ë©”ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    # ë¹„ë™ê¸° ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
    asyncio.run(main())
'''

# ì„¤ì • íŒŒì¼ ì˜ˆì œ ìƒì„±
config_yaml_content = '''# config.yaml - LangGraph RAG ì‹œìŠ¤í…œ ì„¤ì • íŒŒì¼

# ì‹œìŠ¤í…œ ì „ë°˜ ì„¤ì •
system:
  log_level: INFO
  max_memory_usage: 1GB
  max_execution_time: 300

# LLM ì„¤ì •
llm:
  default_model: gpt-4o-mini
  temperature: 0.1
  max_tokens: 1000
  timeout: 30

# ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
vector_db:
  default_type: faiss  # pinecone, faiss, memory ì¤‘ ì„ íƒ
  embedding_model: text-embedding-3-small
  chunk_size: 1000
  chunk_overlap: 200
  
  # Pinecone ì„¤ì • (ì‚¬ìš©ì‹œ)
  pinecone:
    environment: us-east-1
    index_name: langgraph-rag
    dimension: 1536
  
  # FAISS ì„¤ì •
  faiss:
    local_path: ./faiss_index
    save_interval: 300  # 5ë¶„ë§ˆë‹¤ ì €ì¥

# RPG (Repository Planning Graph) ì„¤ì •
rpg:
  max_nodes: 50
  max_execution_time: 600
  enable_parallel_execution: true
  template_path: ./templates/rpg

# ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì„¤ì •
memory:
  short_term_size: 100
  short_term_ttl: 3600  # 1ì‹œê°„
  long_term_cache_size: 1000
  cleanup_interval: 300  # 5ë¶„

# ë„ë©”ì¸ë³„ ì„¤ì •
domains:
  hr:
    index_name: hr-rules
    documents_path: ./data/hr
    specialized_agents:
      - hr_policy_expert
      - hr_procedure_guide
    
  general:
    index_name: general-docs
    documents_path: ./data/general
    
  academic:
    index_name: academic-papers
    documents_path: ./data/papers

# ì—ì´ì „íŠ¸ ì„¤ì •
agents:
  llm_agents:
    gen:
      model: gpt-4o-mini
      temperature: 0.1
      max_tokens: 1500
    router1:
      model: gpt-4o-mini
      temperature: 0.0
      max_tokens: 500
    router2:
      model: gpt-4o-mini
      temperature: 0.0
      max_tokens: 500
  
  autonomous:
    max_iterations: 10
    planning_depth: 3
    enable_self_correction: true
  
  coordinator:
    max_concurrent_agents: 5
    timeout_per_agent: 60

# ë¼ìš°íŒ… ì„¤ì •
routing:
  confidence_threshold: 0.7
  enable_llm_routing: true
  enable_rpg_routing: true
  fallback_route: rag_answer

# ë„êµ¬ ì„¤ì •
tools:
  enable_file_tools: true
  enable_web_tools: false  # ë³´ì•ˆìƒ ê¸°ë³¸ ë¹„í™œì„±í™”
  enable_database_tools: true
  tool_timeout: 30

# ëª¨ë‹ˆí„°ë§ ì„¤ì •
monitoring:
  enable_metrics: true
  enable_profiling: true
  history_limit: 1000
  log_file: langgraph_rag.log

# ë³´ì•ˆ ì„¤ì •
security:
  enable_input_validation: true
  max_input_length: 10000
  allowed_file_extensions:
    - .txt
    - .md
    - .pdf
    - .docx
  blocked_patterns:
    - "<script"
    - "javascript:"
    - "eval("
'''

# README íŒŒì¼ ìƒì„±
readme_content = '''# LangGraph RAG with RPG - ê²½ëŸ‰í™”ëœ Agentic AI ì‹œìŠ¤í…œ

Repository Planning Graph(RPG) ë…¼ë¬¸ì˜ í•µì‹¬ ë¡œì§ì„ ê²½ëŸ‰í™”í•˜ì—¬ LangGraph RAGì— í†µí•©í•œ ì°¨ì„¸ëŒ€ AI ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” íŠ¹ì§•

### âœ¨ RPG(Repository Planning Graph) í†µí•©
- ë…¼ë¬¸ì˜ RPG ë¡œì§ì„ ê²½ëŸ‰í™”í•˜ì—¬ êµ¬í˜„
- 3ë‹¨ê³„ ì‹¤í–‰: Planning â†’ Refinement â†’ Execution
- HTIL(Human-in-the-Loop)ì„ íš¨ìœ¨ì ìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” ììœ¨ ì‹¤í–‰ ì‹œìŠ¤í…œ

### ğŸ§  Agentic AI ì™„ì „ êµ¬í˜„
- **LLM**: ë‹¤ì–‘í•œ ì—­í• ë³„ ì–¸ì–´ ëª¨ë¸ ì—ì´ì „íŠ¸
- **Autonomy**: ëª©í‘œ ì§€í–¥ì  ììœ¨ ê³„íš ë° ì‹¤í–‰
- **Memory**: ë‹¨ê¸°/ì¥ê¸° ë©”ëª¨ë¦¬ ë¶„ë¦¬ ê´€ë¦¬
- **Tool**: í”ŒëŸ¬ê·¸ì¸ ë°©ì‹ì˜ ë„êµ¬ ì‹œìŠ¤í…œ

### ğŸ—ï¸ ëª¨ë“ˆì‹ ì•„í‚¤í…ì²˜
- 9ê°œ ë…ë¦½ ëª¨ë“ˆë¡œ êµ¬ì„±ëœ Composable ì„¤ê³„
- ë²¤ë” ì¢…ì†ì„± ì—†ëŠ” ì¶”ìƒí™” ê³„ì¸µ
- ë„ë©”ì¸ë³„ ë™ì  ì ì‘ ì‹œìŠ¤í…œ

### ğŸ¯ ìµœì‹  í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
- 2024-2025 ìµœì‹  ê¸°ë²• ì ìš©
- ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì—”ì§„
- ì—­í• ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ìµœì í™”

## ğŸ“ ëª¨ë“ˆ êµ¬ì¡°

```
â”œâ”€â”€ state.py          # í†µí•© ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ
â”œâ”€â”€ rpg.py             # Repository Planning Graph êµ¬í˜„
â”œâ”€â”€ memory.py          # Agentic AI Memory ì‹œìŠ¤í…œ
â”œâ”€â”€ tools.py           # Tool ì¸í„°í˜ì´ìŠ¤ ê´€ë¦¬
â”œâ”€â”€ agents.py          # Agentic êµ¬ì„± ìš”ì†Œ (LLM, Autonomy)
â”œâ”€â”€ db.py              # ë²¤ë” ë…ë¦½ì  ë°ì´í„°ë² ì´ìŠ¤ ì¶”ìƒí™”
â”œâ”€â”€ router.py          # ì§€ëŠ¥í˜• ë¼ìš°íŒ… ì‹œìŠ¤í…œ
â”œâ”€â”€ utils.py           # ê³µí†µ ìœ í‹¸ë¦¬í‹° (í”„ë¡¬í”„íŠ¸, ì„¤ì •, ëª¨ë‹ˆí„°ë§)
â”œâ”€â”€ graph.py           # í†µí•© ê·¸ë˜í”„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
â””â”€â”€ requirements.txt   # ì˜ì¡´ì„± ê´€ë¦¬
```

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì„¤ì •

### 1. í™˜ê²½ ì„¤ì •
```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv venv
source venv/bin/activate  # Windows: venv\\Scripts\\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
```bash
# .env íŒŒì¼ ìƒì„±
OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key  # ì„ íƒì‚¬í•­
```

### 3. ì„¤ì • íŒŒì¼
`config.yaml` íŒŒì¼ì—ì„œ ì‹œìŠ¤í…œ ì„¤ì •ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ® ì‚¬ìš©ë²•

### ê°„ë‹¨í•œ ì‚¬ìš©
```python
import asyncio
from graph import run_rag_system

async def main():
    # ê¸°ë³¸ RAG ëª¨ë“œ
    result = await run_rag_system("ì—°ì°¨ëŠ” ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?", mode="standard")
    print(result['answer'])
    
    # RPG ê°•í™” ëª¨ë“œ  
    result = await run_rag_system("ë³µì¡í•œ ì—…ë¬´ í”„ë¡œì„¸ìŠ¤ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”", mode="rpg")
    print(result['answer'])
    
    # ììœ¨ ì—ì´ì „íŠ¸ ëª¨ë“œ
    result = await run_rag_system("ìë™ìœ¼ë¡œ ìµœì í™”í•´ì£¼ì„¸ìš”", mode="autonomous")
    print(result['answer'])

asyncio.run(main())
```

### ê³ ê¸‰ ì‚¬ìš© (ìˆ˜ë™ êµ¬ì„±)
```python
from graph import GraphOrchestrator, GraphMode

# ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ìƒì„±
orchestrator = GraphOrchestrator()
orchestrator.initialize_components()

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
await orchestrator.database_manager.connect_database("faiss")

# ê·¸ë˜í”„ ë¹Œë“œ ë° ì‹¤í–‰
orchestrator.build_graph(GraphMode.RPG_ENHANCED)
result = await orchestrator.run("ì‚¬ìš©ì ì§ˆë¬¸")
```

## ğŸ”§ ì£¼ìš” ê¸°ëŠ¥

### 1. RPG ê¸°ë°˜ ì§€ëŠ¥í˜• ê³„íš
- ì‚¬ìš©ì ìš”ì²­ì„ ëŠ¥ë ¥ ê·¸ë˜í”„ë¡œ ë¶„í•´
- ì˜ì¡´ì„± ê¸°ë°˜ ì‹¤í–‰ ìˆœì„œ ìë™ ê²°ì •
- ì‹¤íŒ¨ ì‹œ ìë™ ë³µêµ¬ ë° ì¬ì‹œë„

### 2. ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í˜‘ì—…
- LLM ì—ì´ì „íŠ¸: í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° ìƒì„± ì „ë‹´
- ììœ¨ ì—ì´ì „íŠ¸: ëª©í‘œ ì§€í–¥ì  ê³„íš ë° ì‹¤í–‰
- ì¡°ì • ì—ì´ì „íŠ¸: ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜

### 3. ì§€ëŠ¥í˜• ë¼ìš°íŒ…
- ê·œì¹™ ê¸°ë°˜ + LLM ê¸°ë°˜ + RPG ê¸°ë°˜ í†µí•© ë¼ìš°íŒ…
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”
- ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë™ì  ê²½ë¡œ ì„ íƒ

### 4. ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
- ë‹¨ê¸° ë©”ëª¨ë¦¬: LRU ê¸°ë°˜ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
- ì¥ê¸° ë©”ëª¨ë¦¬: ë²¡í„° ì €ì¥ì†Œ ì—°ë™ ì§€ì‹ ê´€ë¦¬
- ìë™ ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ì´ì£¼ ê¸°ëŠ¥

### 5. ë„êµ¬ ìƒíƒœê³„
- ë²¡í„° ê²€ìƒ‰, ë°ì´í„°ë² ì´ìŠ¤, API, íŒŒì¼ ì‹œìŠ¤í…œ ë„êµ¬
- ë¹„ë™ê¸° ì‹¤í–‰ ë° ì²´ì¸ ì²˜ë¦¬
- ì‚¬ìš© í†µê³„ ë° ì„±ëŠ¥ ë¶„ì„

## ğŸŒŸ RPG í•µì‹¬ ê°œë…

### ë…¼ë¬¸ì˜ RPG ë¡œì§ êµ¬í˜„
1. **Proposal-level Planning**: ì‚¬ìš©ì ìš”ì²­ì„ ê¸°ëŠ¥ ë…¸ë“œë¡œ ë¶„í•´
2. **Implementation-level Refinement**: ê¸°ëŠ¥ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¨ìœ„ë¡œ ì •ì œ  
3. **Graph-guided Execution**: ì˜ì¡´ì„± ê·¸ë˜í”„ ê¸°ë°˜ ìˆœì°¨ ì‹¤í–‰

### HTIL ëŒ€ì²´ ë©”ì»¤ë‹ˆì¦˜
- ì‚¬ëŒì˜ ê°œì… ì—†ì´ ììœ¨ì  ì˜ì‚¬ê²°ì •
- ì‹¤íŒ¨ ì‹œ ìë™ ë³µêµ¬ ë° ê°œì„ 
- ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë™ì  ê³„íš ìˆ˜ì •

## ğŸ”„ ì•„í‚¤í…ì²˜ ì›ì¹™

### Composability (ì¡°í•©ì„±)
- ê° ëª¨ë“ˆì€ ë…ë¦½ì ìœ¼ë¡œ êµì²´ ê°€ëŠ¥
- ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜ ëŠìŠ¨í•œ ê²°í•©
- ëŸ°íƒ€ì„ ì˜ì¡´ì„± ì£¼ì…

### Vendor Independence (ë²¤ë” ë…ë¦½ì„±)  
- Pinecone, FAISS, ë¡œì»¬ ë©”ëª¨ë¦¬ DB ì§€ì›
- OpenAI ì™¸ ë‹¤ë¥¸ LLM ì œê³µì ì§€ì› ê°€ëŠ¥
- í´ë¼ìš°ë“œ ë° ì˜¨í”„ë ˆë¯¸ìŠ¤ ë°°í¬ ì§€ì›

### Domain Agnostic (ë„ë©”ì¸ ë¬´ê´€ì„±)
- ì„¤ì • ê¸°ë°˜ ë„ë©”ì¸ í…œí”Œë¦¿
- ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
- ì—…ë¬´ë³„ íŠ¹í™” ì—ì´ì „íŠ¸ êµ¬ì„±

## ğŸ“Š ì„±ëŠ¥ ë° ëª¨ë‹ˆí„°ë§

### ë‚´ì¥ ëª¨ë‹ˆí„°ë§
- ì‹¤í–‰ ì‹œê°„ ë° ì„±ê³µë¥  ì¶”ì 
- ì»´í¬ë„ŒíŠ¸ë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

### í”„ë¡œíŒŒì¼ë§
```python
from utils import profile

with profile("custom_operation"):
    # ì¸¡ì •í•˜ê³  ì‹¶ì€ ì½”ë“œ
    pass
```

### ì„¤ì • ê¸°ë°˜ íŠœë‹
- YAML ê¸°ë°˜ ì‹¤ì‹œê°„ ì„¤ì • ë³€ê²½
- A/B í…ŒìŠ¤íŠ¸ ì§€ì›
- ì„±ëŠ¥ ì„ê³„ê°’ ì•ŒëŒ

## ğŸ¤ ê¸°ì—¬ ê°€ì´ë“œ

### ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ ì¶”ê°€
```python
from agents import BaseAgent, AgentType

class CustomAgent(BaseAgent):
    def __init__(self, name: str):
        super().__init__(name, AgentType.CUSTOM)
    
    async def execute(self, task: str, context: Dict, state: ComposableState):
        # ì—ì´ì „íŠ¸ ë¡œì§ êµ¬í˜„
        pass
```

### ìƒˆë¡œìš´ ë„êµ¬ ì¶”ê°€
```python
from tools import BaseTool, ToolType

class CustomTool(BaseTool):
    def __init__(self):
        super().__init__("custom_tool", "ì„¤ëª…", ToolType.CUSTOM)
    
    async def execute(self, **kwargs):
        # ë„êµ¬ ë¡œì§ êµ¬í˜„
        pass
```

## ğŸ“ˆ ë¡œë“œë§µ

### v1.1 (ì˜ˆì •)
- [ ] ë‹¤êµ­ì–´ ì§€ì›
- [ ] ì›¹ UI ëŒ€ì‹œë³´ë“œ
- [ ] ê³ ê¸‰ RAG ê¸°ë²• (HyDE, CoVe)

### v1.2 (ì˜ˆì •)  
- [ ] ë¶„ì‚° ì²˜ë¦¬ ì§€ì›
- [ ] ì»¤ìŠ¤í…€ LLM ì œê³µì ì¶”ê°€
- [ ] ê³ ê¸‰ ë©”ëª¨ë¦¬ ì••ì¶•

## ğŸ› ì´ìŠˆ ë° ì§€ì›

ë²„ê·¸ ë¦¬í¬íŠ¸ë‚˜ ê¸°ëŠ¥ ìš”ì²­ì€ Issuesì— ë“±ë¡í•´ ì£¼ì„¸ìš”.

## ğŸ“„ ë¼ì´ì„¼ìŠ¤

MIT License - ììœ ë¡­ê²Œ ì‚¬ìš©, ìˆ˜ì •, ë°°í¬ ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

**Built with â¤ï¸ by the LangGraph RPG Team**

*"ë…¼ë¬¸ì˜ í˜ì‹ ì„ ì‹¤ì œ ì½”ë“œë¡œ êµ¬í˜„í•˜ì—¬, ëˆ„êµ¬ë‚˜ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê²½ëŸ‰í™”ëœ Agentic AI ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤."*
'''

# íŒŒì¼ë“¤ ì €ì¥
with open('usage_example.py', 'w', encoding='utf-8') as f:
    f.write(usage_example_content)

with open('config.yaml', 'w', encoding='utf-8') as f:
    f.write(config_yaml_content)

with open('README.md', 'w', encoding='utf-8') as f:
    f.write(readme_content)

print("âœ… ì¶”ê°€ íŒŒì¼ë“¤ ìƒì„± ì™„ë£Œ!")
print(f"usage_example.py í¬ê¸°: {len(usage_example_content)} ë¬¸ì")
print(f"config.yaml í¬ê¸°: {len(config_yaml_content)} ë¬¸ì")
print(f"README.md í¬ê¸°: {len(readme_content)} ë¬¸ì")

print("\nğŸ‰ LangGraph RPG RAG ì‹œìŠ¤í…œ ë¦¬íŒ©í„°ë§ ì™„ë£Œ!")
print("=" * 60)
print("ğŸ“ ìƒì„±ëœ íŒŒì¼ ëª©ë¡:")
file_list = [
    "state.py", "rpg.py", "memory.py", "tools.py", "agents.py",
    "db.py", "router.py", "utils.py", "graph.py", "requirements.txt",
    "usage_example.py", "config.yaml", "README.md"
]

for i, file_name in enumerate(file_list, 1):
    print(f"{i:2d}. {file_name}")

print(f"\nğŸ“Š ì´ {len(file_list)}ê°œ íŒŒì¼ ìƒì„±")
print("\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
print("1. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (.env íŒŒì¼)")
print("2. pip install -r requirements.txt")
print("3. python usage_example.py")
print("4. ë¬¸ì„œ ë°ì´í„°ë¥¼ ./data/ í´ë”ì— ì¤€ë¹„")
print("5. config.yamlì—ì„œ ì„¤ì • ì¡°ì •")

print("\nâœ¨ ì£¼ìš” í˜ì‹  ì‚¬í•­:")
print("- ğŸ“ˆ RPG ë…¼ë¬¸ ë¡œì§ì˜ ì‹¤ìš©ì  ê²½ëŸ‰í™”")
print("- ğŸ¤– ì™„ì „í•œ Agentic AI êµ¬ì„± ìš”ì†Œ êµ¬í˜„")  
print("- ğŸ”§ HTIL ëŒ€ì²´ ììœ¨ ì‹œìŠ¤í…œ")
print("- ğŸŒ ë²¤ë” ë…ë¦½ì  ì•„í‚¤í…ì²˜")
print("- ğŸ“ ìµœì‹  í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§")
print("- ğŸ”€ Composable ëª¨ë“ˆ ì„¤ê³„")