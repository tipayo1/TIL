{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90879e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== QA ===\n",
      "- 외부 지식 소스 연결 및 벡터 인덱스: RAG의 기본은 외부 데이터 소스(문서/데이터베이스)를 검색 가능한 상태로 연결하고, 문서 조각을 벡터 공간에 인덱싱해 유사도 기반으로 관련 자료를 찾는 것(랭체인 RAG의 벡터 기반 검색 아이디어 및 외부 소스 연결 접근; 3. 그래프 RAG 특징). 근거: (랭체인 RAG 와 graph RAG의 차이.md, 1. 이번 주에 배운 내용이 랭체인과 RAG를 다루는 데 주는 도움), (랭체인 RAG 와 graph RAG의 차이.md, 3. 그래프 RAG(Graph RAG) 특징).\n",
      "\n",
      "- 검색/증강 모듈 (Retriever): 질의 맥락에 맞는 문서를 찾아 LLM에 전달하는 역할로, “유사한 것”을 벡터 공간에서 찾아주는 방식이 핵심이라는 설명이 포함됨. 근거: (랭체인 RAG 와 graph RAG의 차이.md, 3. 그래프 RAG 특징), (20250703 perplexity 학습내용.md, 핵심 요약).\n",
      "\n",
      "- LLM 기반 생성 엔진: 검색된 자료를 바탕으로 최종 응답을 생성하는 생성기 역할이 core로 언급됨. 근거: (20250703 perplexity 학습내용.md, 핵심 요약).\n",
      "\n",
      "- 컨텍스트 결합 및 증거 제시 기능: 검색 결과를 실제 응답의 증거로 인용하고, 맥락과 함께 제시하는 방식으로 응답의 신뢰성을 높임. 이는 RAG의 “생성에 증거를 연결하는” 특성과도 맞물림. 근거: (20250703 perplexity 학습내용.md, 핵심 요약).\n",
      "\n",
      "- 그라운딩 및 다중 홉 추론(특히 Graph RAG에서의 차별점): Graph RAG의 특징으로, 지식 그래프를 이용한 다중 홉 추론, 설명 가능성, 데이터 통합 등 복잡한 맥락의 연쇄 추론이 가능한 점이 강조됨. 이 부분은 랭체인 RAG와의 차이를 설명하는 문맥에서도 확인 가능. 근거: (랭체인 RAG 와 graph RAG의 차이.md, 3. 그래프 RAG(Graph RAG) 특징), (랭체인 RAG 와 graph RAG의 차이.md, 4. 요약).\n",
      "\n",
      "- 파이프라인 오케스트레이션/구현 방식: 랭체인 기반의 데이터 파이프라인 구성으로, 검색과 생성 흐름의 연결 방식이 핵심으로 다뤄짐. 근거: (랭체인 RAG 와 graph RAG의 차이.md, 1. 이번 주에 배운 내용이 랭체인과 RAG를 다루는 데 주는 도움).\n",
      "\n",
      "- 요약 관점의 핵심 차이 포인트: 랭체인 RAG는 벡터 기반의 “유사성 찾기”에 초점을 두고, Graph RAG는 그래프 구조를 통한 연결성/다중 홉 추론에 강점이 있으며, 상황에 따라 적합한 방식을 선택해야 한다는 점. 근거: (랭체인 RAG 와 graph RAG의 차이.md, 4. 요약).\n",
      "\n",
      "출처(가능한 경우 페이지/섹션 포함):\n",
      "- 랭체인 RAG 와 graph RAG의 차이.md: 1. 이번 주에 배운 내용이 랭체인과 RAG를 다루는 데 주는 도움, 3. 그래프 RAG(Graph RAG) 특징, 4. 요약\n",
      "- 20250703 perplexity 학습내용.md: 핵심 요약\n",
      "- 커서에서는 이걸 이용하시면 diff등 다양하게 CC와 연동해서 작업이 가능합니다. 공식 확.md: 그라운딩과 RAG의 관계 및 차이(참고 문맥)\n",
      "\n",
      "=== QUIZ ===\n",
      "다음은 “지도학습과 비지도학습 차이”를 주제로 한 5문항 객관식 퀴즈입니다.\n",
      "\n",
      "1) Q1. 지도학습과 비지도학습의 기본 차이는 무엇인가?\n",
      "- A) 지도학습은 라벨이 있는 데이터로 학습하고, 비지도학습은 라벨 없이 학습한다.\n",
      "- B) 지도학습은 비지도학습보다 항상 빠르다.\n",
      "- C) 지도학습은 항상 군집화를 수행하고, 비지도학습은 예측을 수행한다.\n",
      "- D) 지도학습과 비지도학습은 동일한 데이터로 학습한다.\n",
      "정답: A\n",
      "- 소스: 벡터화(vectorization)와 머신러닝의 관계 및 세부 분류.md\n",
      "- 문맥: 데이터 전처리 단계에서의 분류 체계에 따라 지도학습/비지도학습 구분이 논의될 수 있음.\n",
      "\n",
      "2) Q2. 지도학습을 선호하는 상황은?\n",
      "- A) 작은 라벨 없는 데이터셋에서 패턴 발견 필요시\n",
      "- B) 라벨이 있는 데이터셋이 있고 특정 목표 예측이 필요한 경우\n",
      "- C) 데이터의 구조만 파악하려는 경우\n",
      "- D) 차원 축소가 필요할 때\n",
      "정답: B\n",
      "- 소스: 벡터화(vectorization)와 머신러닝의 관계 및 세부 분류.md\n",
      "- 문맥: 지도학습은 목표 변수를 예측하기 위해 라벨이 있는 데이터를 필요로 함.\n",
      "\n",
      "3) Q3. 비지도학습의 전형적 예로 올바른 것은?\n",
      "- A) 회귀를 통한 가격 예측\n",
      "- B) 분류기를 학습시켜 이미지 분류\n",
      "- C) 군집화나 차원 축소 같은 데이터 구조 발견\n",
      "- D) 라벨링된 데이터로 감정 분석 학습\n",
      "정답: C\n",
      "- 소스: 벡터화(vectorization)와 머신러닝의 관계 및 세부 분류.md\n",
      "- 문맥: 비지도학습은 라벨이 없는 데이터에서 구조나 패턴을 발견하는 것을 주로 다룸.\n",
      "\n",
      "4) Q4. 데이터 파이프라인에서 일반적으로 데이터 전처리 단계로써 벡터화가 수행되며, 지도/비지도 구분은 어디에서 다루어지는가?\n",
      "- A) 모델 학습 단계\n",
      "- B) 데이터 전처리 단계에서 구분\n",
      "- C) 결과 평가 단계\n",
      "- D) 데이터 라벨링 단계\n",
      "정답: B\n",
      "- 소스: 벡터화(vectorization)와 머신러닝의 관계 및 세부 분류.md\n",
      "- 문맥: 벡터화는 데이터 전처리/특징공학의 한 부분으로, 이후의 지도학습 여부 결정에 영향을 미침.\n",
      "\n",
      "5) Q5. 파인튜닝 맥락에서 지도학습 기반 파인튜닝은 어떤 데이터가 필요하다고 명시되어 있는가?\n",
      "- A) 라벨이 없는 대규모 데이터\n",
      "- B) 라벨이 있는 데이터셋\n",
      "- C) 라벨링 없이도 수행 가능\n",
      "- D) 모델 아키텍처 변경만 필요\n",
      "정답: B\n",
      "- 소스: llm파인튜닝의 과정을 도식화.pdf\n",
      "- 문맥: 파인튜닝에서 “레이블이 있는 데이터셋을 사용”하는 지도학습 기반 접근이 언급됨.\n",
      "\n",
      "=== SUMMARY ===\n",
      "- **벡터의 크기(magnitude)**와 방향이 모델마다 다르므로, 같은 쿼리라도 모델 간에 코사인 유사도 계산이 왜곡될 수 있습니다. (구체적 사례: “벡터 크기 차이”에 따른 혼란)\n",
      "- 같은 단어라도 **의미적 표현의 차이**가 커져, 모델 간의 임베딩 공간에서 같은 단어가 서로 다른 관계를 가질 수 있습니다. 예: \"cat\"과 \"dog\"의 상대적 거리 차이\n",
      "- 서로 다른 임베딩 공간을 혼합하면 검색/추천 시스템이 엉망이 될 수 있으며, **공간 간 호환성 관리**가 필수적입니다. (실무 예: 데이터베이스의 임베딩 공간 불일치)\n",
      "- 이를 완화하기 위한 주요 기법으로 **정규화(단위 벡터화, 평균 제거, 화이트닝)**와 **정렬/정렬 기술(Alignment, Procrustes 변환)**이 제시됩니다. 공통 앵커 단어를 활용한 변환도 포함됩니다.\n",
      "- 최근 연구로는 **vec2vec** 및 **Embedding-Converter 프레임워크**가 제시되어 서로 다른 임베딩 공간 간의 변환과 원활한 전환 가능성을 보여줍니다. 또한 실무 차원의 일관성 유지와 전체 재구축이 권장됩니다.\n",
      "\n",
      "(근거: 20250626 1주 4일차 Perplexity를 활용한 수업시간 외 추가공부(임베딩, MCP, 오케스트레이션에이전트, 토큰, subword부분어 토큰화).md; 20250626 1주 4일차 Perplexity를 활용한 수업시간 외 추가공부(임베딩, MCP, 오케스트레이션에이전트, 토큰, subword부분어 토큰화) (2).md)\n",
      "\n",
      "[출처를 참조한 맥락 요약]\n",
      "- 구체적 충돌 사례 및 해결 방향: 벡터 크기, 의미적 표현의 차이, 검색 시스템의 혼란\n",
      "- 실무적 대응: 단일 모델 일관성, 전체 재구축 필요성\n",
      "- vec2vec 및 Embedding-Converter 프레임워크: 공간 간 변환 및 비용 절감 가능성\n",
      "- 결론: 임베딩의 광범위한 활용과 범용성 강조\n",
      "\n",
      "Source bodies: (파일: \"20250626 1주 4일차 Perplexity를 활용한 수업시간 외 추가공부(임베딩, MCP, 오케스트레이션에이전트, 토큰, subword부분어 토큰화).md\", 구체적 구절), (파일: \"20250626 1주 4일차 Perplexity를 활용한 수업시간 외 추가공부(임베딩, MCP, 오케스트레이션에이전트, 토큰, subword부분어 토큰화) (2).md\", 구체적 구절)]\n"
     ]
    }
   ],
   "source": [
    "# 2. 학습 조교 에이전트 (RAG-수업자료)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import glob, os\n",
    "from typing import Literal, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Loaders / Splitters / Vectorstore\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# LCEL\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Retrieval enhancers\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "\n",
    "@dataclass\n",
    "class TAConfig:\n",
    "    study_dir: str = \"./mystudy\"\n",
    "    index_path: Optional[str] = \"./faiss_index\"   # None이면 메모리 전용\n",
    "    chunk_size: int = 500\n",
    "    chunk_overlap: int = 50\n",
    "    k: int = 5\n",
    "    model: str = \"gpt-5-nano\"                     # 원 코드와 호환\n",
    "    temperature: float = 0.2\n",
    "    use_multi_query: bool = True\n",
    "    use_compression: bool = True                 # Embeddings 기반 필터\n",
    "    similarity_threshold: float = 0.3            # 압축 필터 기준\n",
    "\n",
    "def load_corpus(study_dir: str):\n",
    "    pdfs = glob.glob(os.path.join(study_dir, \"*.pdf\"))\n",
    "    mds  = glob.glob(os.path.join(study_dir, \"*.md\"))\n",
    "    docs = []\n",
    "\n",
    "    for p in pdfs:\n",
    "        dlist = PyMuPDFLoader(p).load()\n",
    "        for d in dlist:\n",
    "            d.metadata[\"file_type\"] = \"pdf\"\n",
    "            d.metadata[\"source_file\"] = os.path.basename(p)\n",
    "        docs.extend(dlist)\n",
    "\n",
    "    for p in mds:\n",
    "        dlist = TextLoader(p, encoding=\"utf-8\").load()\n",
    "        for d in dlist:\n",
    "            d.metadata[\"file_type\"] = \"markdown\"\n",
    "            d.metadata[\"source_file\"] = os.path.basename(p)\n",
    "        docs.extend(dlist)\n",
    "\n",
    "    return docs\n",
    "\n",
    "def build_vectorstore(docs, cfg: TAConfig):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=cfg.chunk_size, chunk_overlap=cfg.chunk_overlap\n",
    "    )\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    # 로컬 인덱스가 있으면 재사용\n",
    "    if cfg.index_path and os.path.isdir(cfg.index_path):\n",
    "        vs = FAISS.load_local(\n",
    "            folder_path=cfg.index_path,\n",
    "            embeddings=embeddings,\n",
    "            allow_dangerous_deserialization=True,  # 신중 사용\n",
    "        )\n",
    "        # 갱신: 신규 청크를 추가(간단 합류)\n",
    "        vs.add_documents(chunks)\n",
    "    else:\n",
    "        vs = FAISS.from_documents(chunks, embeddings)\n",
    "        if cfg.index_path:\n",
    "            os.makedirs(cfg.index_path, exist_ok=True)\n",
    "            vs.save_local(cfg.index_path)\n",
    "\n",
    "    return vs\n",
    "\n",
    "def build_retriever(vs: FAISS, cfg: TAConfig):\n",
    "    base = vs.as_retriever(search_kwargs={\"k\": cfg.k})\n",
    "\n",
    "    if cfg.use_multi_query:\n",
    "        llm_q = ChatOpenAI(model=cfg.model, temperature=0)\n",
    "        base = MultiQueryRetriever.from_llm(retriever=base, llm=llm_q)\n",
    "\n",
    "    if cfg.use_compression:\n",
    "        compressor = EmbeddingsFilter(\n",
    "            embeddings=OpenAIEmbeddings(),\n",
    "            similarity_threshold=cfg.similarity_threshold,\n",
    "        )\n",
    "        base = ContextualCompressionRetriever(\n",
    "            base_retriever=base, base_compressor=compressor\n",
    "        )\n",
    "    return base\n",
    "\n",
    "BASE_TEMPLATE = \"\"\"당신은 제공된 수업자료를 기반으로 답변하는 학습 조교입니다.\n",
    "규칙:\n",
    "- 제공된 context 범위 안에서만 답하세요.\n",
    "- 핵심을 요약하고, 근거가 된 소스 파일명(가능 시 페이지/섹션)을 괄호로 덧붙이세요.\n",
    "- 자료에 없으면 \"제공된 자료에서 해당 정보를 찾을 수 없습니다\"라고만 답하세요.\n",
    "\n",
    "[context]\n",
    "{context}\n",
    "\n",
    "[question]\n",
    "{question}\n",
    "\n",
    "[answer]\n",
    "\"\"\"\n",
    "\n",
    "QUIZ_TEMPLATE = \"\"\"당신은 수업자료 기반 퀴즈 제작 조교입니다.\n",
    "규칙:\n",
    "- 5문항 객관식(보기 4개, 정답 표시)으로 생성하세요.\n",
    "- 각 문항 아래 근거가 된 소스 파일명과 문맥을 간단히 덧붙이세요.\n",
    "- 자료에 없으면 \"제공된 자료에서 퀴즈 근거를 찾을 수 없습니다\"라고만 답하세요.\n",
    "\n",
    "[context]\n",
    "{context}\n",
    "\n",
    "[topic_or_question]\n",
    "{question}\n",
    "\n",
    "[quiz]\n",
    "\"\"\"\n",
    "\n",
    "SUMMARY_TEMPLATE = \"\"\"당신은 수업자료 기반 요약 조교입니다.\n",
    "규칙:\n",
    "- 핵심 개념을 5줄 내외로 요약하고, 중요한 용어는 **굵게** 표시하세요.\n",
    "- 근거가 된 소스 파일명과 문맥을 괄호로 덧붙이세요.\n",
    "- 자료에 없으면 \"제공된 자료에서 해당 내용을 찾을 수 없습니다\"라고만 답하세요.\n",
    "\n",
    "[context]\n",
    "{context}\n",
    "\n",
    "[topic]\n",
    "{question}\n",
    "\n",
    "[summary]\n",
    "\"\"\"\n",
    "\n",
    "def build_chain(retriever, template: str, cfg: TAConfig):\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    llm = ChatOpenAI(model=cfg.model, temperature=cfg.temperature)\n",
    "    chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "Task = Literal[\"qa\", \"quiz\", \"summary\"]\n",
    "\n",
    "class StudyTeachingAssistant:\n",
    "    def __init__(self, cfg: TAConfig = TAConfig()):\n",
    "        self.cfg = cfg\n",
    "        docs = load_corpus(cfg.study_dir)\n",
    "        self.vectorstore = build_vectorstore(docs, cfg)\n",
    "        self.retriever = build_retriever(self.vectorstore, cfg)\n",
    "        self.qa_chain = build_chain(self.retriever, BASE_TEMPLATE, cfg)\n",
    "        self.quiz_chain = build_chain(self.retriever, QUIZ_TEMPLATE, cfg)\n",
    "        self.summary_chain = build_chain(self.retriever, SUMMARY_TEMPLATE, cfg)\n",
    "\n",
    "    def invoke(self, question: str, task: Task = \"qa\") -> str:\n",
    "        if task == \"qa\":\n",
    "            return self.qa_chain.invoke(question)\n",
    "        if task == \"quiz\":\n",
    "            return self.quiz_chain.invoke(question)\n",
    "        if task == \"summary\":\n",
    "            return self.summary_chain.invoke(question)\n",
    "        raise ValueError(\"Unsupported task\")\n",
    "\n",
    "    def refresh(self):\n",
    "        # 신규 파일 반영(간단 재색인+병합)\n",
    "        docs = load_corpus(self.cfg.study_dir)\n",
    "        self.vectorstore = build_vectorstore(docs, self.cfg)\n",
    "        self.retriever = build_retriever(self.vectorstore, self.cfg)\n",
    "        self.qa_chain = build_chain(self.retriever, BASE_TEMPLATE, self.cfg)\n",
    "        self.quiz_chain = build_chain(self.retriever, QUIZ_TEMPLATE, self.cfg)\n",
    "        self.summary_chain = build_chain(self.retriever, SUMMARY_TEMPLATE, self.cfg)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfg = TAConfig(\n",
    "        study_dir=\"./mystudy\",\n",
    "        index_path=\"./faiss_index\",\n",
    "        use_multi_query=True,\n",
    "        use_compression=True,\n",
    "        k=5,\n",
    "        model=\"gpt-5-nano\",\n",
    "    )\n",
    "    ta = StudyTeachingAssistant(cfg)\n",
    "    print(\"=== QA ===\")\n",
    "    print(ta.invoke(\"강의에서 다룬 RAG의 핵심 구성요소를 정리해줘\", task=\"qa\"))\n",
    "    print(\"\\n=== QUIZ ===\")\n",
    "    print(ta.invoke(\"지도학습과 비지도학습 차이\", task=\"quiz\"))\n",
    "    print(\"\\n=== SUMMARY ===\")\n",
    "    print(ta.invoke(\"벡터 임베딩과 유사도 검색\", task=\"summary\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
