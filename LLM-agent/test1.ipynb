{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9d4de95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tipay\\AppData\\Local\\Temp\\ipykernel_16284\\2834682981.py:257: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  print(report.json(indent=2, ensure_ascii=False))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "`dumps_kwargs` keyword arguments are no longer supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 257\u001b[39m\n\u001b[32m    255\u001b[39m agent = CompanyReportAgent()\n\u001b[32m    256\u001b[39m report = agent.generate_report(spec)\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mreport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tipay\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydantic\\main.py:1317\u001b[39m, in \u001b[36mBaseModel.json\u001b[39m\u001b[34m(self, include, exclude, by_alias, exclude_unset, exclude_defaults, exclude_none, encoder, models_as_dict, **dumps_kwargs)\u001b[39m\n\u001b[32m   1315\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mThe `models_as_dict` argument is no longer supported; use a model serializer instead.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dumps_kwargs:\n\u001b[32m-> \u001b[39m\u001b[32m1317\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33m`dumps_kwargs` keyword arguments are no longer supported.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1318\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_dump_json(\n\u001b[32m   1319\u001b[39m     include=include,\n\u001b[32m   1320\u001b[39m     exclude=exclude,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1324\u001b[39m     exclude_none=exclude_none,\n\u001b[32m   1325\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: `dumps_kwargs` keyword arguments are no longer supported."
     ]
    }
   ],
   "source": [
    "# company_report_agent_final.py\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import glob, os\n",
    "from typing import List, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Document loaders / splitter / vectorstore\n",
    "from langchain_community.document_loaders import PyMuPDFLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# LCEL\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Structured output\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Retrieval enhancers\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IndexConfig:\n",
    "    study_dir: str = \"./mystudy\"\n",
    "    index_path: Optional[str] = \"./faiss_index\"\n",
    "    chunk_size: int = 500\n",
    "    chunk_overlap: int = 50\n",
    "    k: int = 4\n",
    "    use_multi_query: bool = True\n",
    "    use_compression: bool = True\n",
    "    similarity_threshold: float = 0.30\n",
    "\n",
    "@dataclass\n",
    "class ReportConfig:\n",
    "    model: str = \"gpt-5-nano\"\n",
    "    temperature: float = 0.2\n",
    "    audience: str = \"임원\"\n",
    "    tone: str = \"격식체, 간결\"\n",
    "    length: str = \"요약+핵심 문단(각 섹션 5문장 이내)\"\n",
    "    citation_style: str = \"말미 인용(source_file, page/section)\"\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1) 코퍼스 로드 / 인덱스 구성\n",
    "# ----------------------------\n",
    "def load_corpus(study_dir: str):\n",
    "    docs = []\n",
    "    for p in glob.glob(os.path.join(study_dir, \"*.pdf\")):\n",
    "        for d in PyMuPDFLoader(p).load():\n",
    "            d.metadata.update(file_type=\"pdf\", source_file=os.path.basename(p))\n",
    "            docs.append(d)\n",
    "    for p in glob.glob(os.path.join(study_dir, \"*.md\")):\n",
    "        for d in TextLoader(p, encoding=\"utf-8\").load():\n",
    "            d.metadata.update(file_type=\"markdown\", source_file=os.path.basename(p))\n",
    "            docs.append(d)\n",
    "    return docs\n",
    "\n",
    "def build_vectorstore(docs, cfg: IndexConfig):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=cfg.chunk_size,\n",
    "        chunk_overlap=cfg.chunk_overlap\n",
    "    )\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    emb = OpenAIEmbeddings()\n",
    "\n",
    "    if cfg.index_path and os.path.isdir(cfg.index_path):\n",
    "        vs = FAISS.load_local(\n",
    "            folder_path=cfg.index_path,\n",
    "            embeddings=emb,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        vs.add_documents(chunks)\n",
    "    else:\n",
    "        vs = FAISS.from_documents(chunks, emb)\n",
    "        if cfg.index_path:\n",
    "            os.makedirs(cfg.index_path, exist_ok=True)\n",
    "            vs.save_local(cfg.index_path)\n",
    "\n",
    "    return vs\n",
    "\n",
    "def build_retriever(vs, cfg: IndexConfig):\n",
    "    base = vs.as_retriever(search_kwargs={\"k\": cfg.k})\n",
    "\n",
    "    if cfg.use_multi_query:\n",
    "        base = MultiQueryRetriever.from_llm(\n",
    "            retriever=base,\n",
    "            llm=ChatOpenAI(temperature=0)\n",
    "        )\n",
    "\n",
    "    if cfg.use_compression:\n",
    "        filt = EmbeddingsFilter(\n",
    "            embeddings=OpenAIEmbeddings(),\n",
    "            similarity_threshold=cfg.similarity_threshold\n",
    "        )\n",
    "        base = ContextualCompressionRetriever(\n",
    "            base_retriever=base,\n",
    "            base_compressor=filt\n",
    "        )\n",
    "\n",
    "    return base\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) 구조화 스키마 정의\n",
    "# ----------------------------\n",
    "class ReportSection(BaseModel):\n",
    "    heading: str = Field(..., description=\"섹션 제목\")\n",
    "    content: str = Field(..., description=\"본문(말미 인용 포함)\")\n",
    "    bullets: List[str] = Field(default_factory=list)\n",
    "\n",
    "class ReportModel(BaseModel):\n",
    "    title: str\n",
    "    executive_summary: str\n",
    "    sections: List[ReportSection]\n",
    "    key_findings: List[str]\n",
    "    risks: List[str]\n",
    "    recommendations: List[str]\n",
    "    references: List[str]\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3) 프롬프트 템플릿\n",
    "# ----------------------------\n",
    "MAP_TEMPLATE = \"\"\"아래 문서 한 조각과 요청 사양(spec)을 바탕으로, 관련성이 높은 증거 3개 이하로 요약하세요.\n",
    "각 항목 말미에 (source_file: 파일명, page: 가능 시) 형태로 인용을 붙이세요.\n",
    "\n",
    "[spec]\n",
    "{spec}\n",
    "\n",
    "[doc_page]\n",
    "{page_content}\n",
    "\n",
    "[meta]\n",
    "source_file={source_file}, page={page}\n",
    "\n",
    "[short_evidence]\n",
    "\"\"\"\n",
    "\n",
    "REDUCE_TEMPLATE = \"\"\"다음은 여러 문서 조각에서 추출한 증거 목록입니다.\n",
    "중복/장황한 내용을 제거하고, 최대 600토큰 내에서 핵심 근거만 남겨 통합하세요.\n",
    "인용 표기는 유지하세요.\n",
    "\n",
    "[evidence_list]\n",
    "{evidence}\n",
    "\n",
    "[consolidated_evidence]\n",
    "\"\"\"\n",
    "\n",
    "REPORT_INSTR = \"\"\"당신은 기업용 보고서 작성 전문가입니다.\n",
    "규칙:\n",
    "- 제공된 context 내부 사실만 사용하고, 각 섹션 본문 말미에 인용({citation_style})을 포함하세요.\n",
    "- 대상({audience}), 문체({tone}), 분량({length})을 준수하세요.\n",
    "- 최종 출력은 JSON 스키마에 맞춰 JSON만 반환하세요. 추가 텍스트 금지.\n",
    "\n",
    "[context]\n",
    "{context}\n",
    "\n",
    "[spec]\n",
    "{spec}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4) 에이전트 정의\n",
    "# ----------------------------\n",
    "class CompanyReportAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        idx_cfg: IndexConfig = IndexConfig(),\n",
    "        rpt_cfg: ReportConfig = ReportConfig()\n",
    "    ):\n",
    "        # 인덱스 및 리트리버 초기화\n",
    "        docs = load_corpus(idx_cfg.study_dir)\n",
    "        vs = build_vectorstore(docs, idx_cfg)\n",
    "        retriever = build_retriever(vs, idx_cfg)\n",
    "\n",
    "        # LLM 및 파서\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=rpt_cfg.model,\n",
    "            temperature=rpt_cfg.temperature\n",
    "        )\n",
    "        self.parser = PydanticOutputParser(pydantic_object=ReportModel)\n",
    "\n",
    "        # Map 체인: 문서별 증거 요약\n",
    "        map_prompt = ChatPromptTemplate.from_template(MAP_TEMPLATE)\n",
    "        map_chain = map_prompt | self.llm | StrOutputParser()\n",
    "\n",
    "        def fanout_map_inputs(x):\n",
    "            items = []\n",
    "            for d in x[\"docs\"]:\n",
    "                items.append({\n",
    "                    \"page_content\": d.page_content,\n",
    "                    \"source_file\": d.metadata.get(\"source_file\", \"\"),\n",
    "                    \"page\": d.metadata.get(\"page\", d.metadata.get(\"page_number\", \"\")),\n",
    "                    \"spec\": x[\"spec\"],\n",
    "                })\n",
    "            return items\n",
    "\n",
    "        self.map_evidence_chain = (\n",
    "            RunnableLambda(fanout_map_inputs)\n",
    "            | map_chain.map()\n",
    "            | RunnableLambda(lambda lst: \"\\n\".join(lst))\n",
    "        )\n",
    "\n",
    "        # Reduce 체인: 증거 통합\n",
    "        reduce_prompt = ChatPromptTemplate.from_template(REDUCE_TEMPLATE)\n",
    "        self.reduce_chain = (\n",
    "            {\"evidence\": self.map_evidence_chain}\n",
    "            | reduce_prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        # 최종 보고서 체인\n",
    "        final_prompt = ChatPromptTemplate.from_template(\n",
    "            REPORT_INSTR + \"\\n{format_instructions}\"\n",
    "        ).partial(\n",
    "            audience=rpt_cfg.audience,\n",
    "            tone=rpt_cfg.tone,\n",
    "            length=rpt_cfg.length,\n",
    "            citation_style=rpt_cfg.citation_style,\n",
    "            format_instructions=self.parser.get_format_instructions()\n",
    "        )\n",
    "\n",
    "        self.chain = (\n",
    "            {\"docs\": retriever, \"spec\": RunnablePassthrough()}\n",
    "            | RunnablePassthrough().assign(context=self.reduce_chain)\n",
    "            | final_prompt\n",
    "            | self.llm\n",
    "            | self.parser\n",
    "        )\n",
    "\n",
    "    def generate_report(self, spec: str) -> ReportModel:\n",
    "        return self.chain.invoke(spec)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5) 사용 예시\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    spec = (\n",
    "        \"목표: RAG 약관/정책 자료의 기업 보고서화 가능성 평가\\n\"\n",
    "        \"범위: 검색/인용/운영비용/리스크/개선안\\n\"\n",
    "        \"요청: 임원 브리핑용 보고서\"\n",
    "    )\n",
    "    agent = CompanyReportAgent()\n",
    "    report = agent.generate_report(spec)\n",
    "    print(report.json(indent=2, ensure_ascii=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
