<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# 데이터 분석 전 과정의 세부 분류

데이터 분석은 문제 정의에서 최종 인사이트 제공 및 실행까지 이어지는 **종합적인 워크플로우**입니다. 각 단계는 서로 유기적으로 연결되며, 아래와 같이 세밀하게 나눌 수 있습니다.

## 1. 문제 정의 및 기획

- 목표 설정
· 비즈니스 혹은 연구 과제에서 해결하고자 하는 핵심 질문을 명확히 규정
- 요구사항 분석
· 관련 이해관계자(경영진, 사용자, 도메인 전문가)와 협업하여 필요 결과물과 제약 조건(예산, 일정, 윤리)을 수집
- 성공 지표 수립
· KPI(핵심성과지표), 평가 메트릭(정확도, RMSE, AUC 등)을 사전에 정의


## 2. 데이터 수집 및 확보

- 데이터 소스 파악
· 내부 시스템(DB, 로그, CRM)·외부 API·공공데이터·크롤링 등
- 데이터 추출(Extraction)
· SQL 쿼리, API 호출, 웹 스크래핑, 파일 입출력(CSV, Excel, JSON)
- 데이터 통합(Integration)
· 이종 소스 간 스키마 정합성 확보, 키 매핑, 조인 연산


## 3. 데이터 저장 및 관리

- 데이터 레이크·웨어하우스 설계
· 원시 데이터(raw)·정제 데이터(cleaned)·분석 데이터(mart) 계층 구성
- 버전 관리 및 거버넌스
· 메타데이터 기록, 데이터 계보(Lineage) 추적, 접근 권한 통제


## 4. 데이터 전처리(Data Preprocessing)

- 결측치 처리
· 제거, 평균·중앙값·최빈값 대체, 예측 모델 활용 보간
- 이상치(Outlier) 탐지 및 처리
· 통계적 방법(IQR, Z-Score), 도메인 룰 기반 필터링
- 중복 및 무의미 데이터 제거
· 유니크 제약, 키 중복 체크
- 형식 변환 및 정규화
· 데이터 타입 일관화(날짜, 문자열, 숫자), 스케일링(Min–Max, 표준화)


## 5. 탐색적 데이터 분석(EDA; Exploratory Data Analysis)

- 기초 통계량 계산
· 평균, 분산, 상관계수, 빈도 분석
- 시각화
· 히스토그램, 박스 플롯, 산점도, 상관관계 히트맵
- 패턴·이상 패턴 발견
· 군집화 기반 시각화, 시계열 트렌드 분석


## 6. 특성 공학(Feature Engineering)

- 특성 선택(Selection)
· 필터(Filter), 래퍼(Wrapper), 임베디드(Embedded) 기법
- 특성 생성(Creation)
· 조합·변환(예: 로그, 다항식), 파생 변수(예: 비율, 날짜 차이)
- 범주형 인코딩(Categorical Encoding)
· 원-핫, 레이블, 타겟 인코딩
- 차원 축소(Dimensionality Reduction)
· PCA, t-SNE, LDA


## 7. 모델링(Modeling)

- 알고리즘 선택
· 회귀, 분류, 군집, 시계열, 추천 시스템 등
- 학습·훈련(Training)
· 하이퍼파라미터 튜닝(Grid/Random Search, Bayesian Optimization)
- 교차 검증(Cross-Validation)
· K-폴드, 계층적 샘플링(Stratified Sampling)
- 앙상블 방법
· 배깅, 부스팅, 스태킹


## 8. 모델 평가 및 검증

- 성능 지표 확인
· 분류: 정확도, 정밀도, 재현율, F1-score, ROC-AUC
· 회귀: MSE, RMSE, MAE, R²
- 오류 분석(Error Analysis)
· 오차 분포, 오분류 사례(review)
- 검증 세트·테스트 세트 평가
· 데이터 누수 방지, 일반화 성능 확인


## 9. 결과 해석 및 시각화

- 특징 중요도(Feature Importance) 분석
· SHAP, LIME, Permutation Importance
- 인사이트 도출
· 도메인 맥락에서 의미 있는 패턴·시사점 정리
- 리포팅
· 대시보드(Tableau, Power BI), 정적 보고서, 프레젠테이션


## 10. 배포 및 운영(Deployment \& Monitoring)

- 모델 서빙(Serving)
· REST API, 배치 프로세스, 스트리밍 파이프라인
- 모니터링(Drift Detection)
· 입력 분포·성능 모니터링, 경보 시스템 설정
- 리트레이닝(모델 업데이트)
· 주기적 재학습, 자동화 파이프라인(CI/CD)


## 11. 피드백 루프 및 지속 개선

- 사용자 피드백 수집
· 모델 예측 결과 검증, 주관적 평가
- A/B 테스트
· 신규 모델 vs 기존 모델 비교 실험
- 성과 리뷰 및 추가 기획
· 개선 지표 설정, 재진행할 단계 식별

***

위 과정을 순환적으로 반복하며 데이터 분석 프로젝트의 **신뢰성**, **유연성**, **효율성**을 지속적으로 높여 나갑니다.

