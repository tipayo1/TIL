<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# 아이솔레이션 포레스트를 반복하면 다 다르게 이상치가 탐지되는데 여러번의 반복한 탐지된 이상치들의 중복된 것을 찾아서 정확한 이상치를 찾을 수 있는가

네, **아이솔레이션 포레스트를 여러 번 반복하여 얻은 중복 이상치들을 활용한 앙상블 접근법으로 더 안정적이고 정확한 이상치 탐지가 가능**합니다.

## 아이솔레이션 포레스트의 불안정성

아이솔레이션 포레스트는 **완전한 무작위 과정**에 기반하기 때문에 `random_state`를 고정하지 않으면 매번 다른 결과를 생성합니다. 이는 다음 요인들 때문입니다:[^1][^2]

- **무작위 특성 선택**: 각 분할에서 특성을 무작위로 선택
- **무작위 분할 값**: 선택된 특성의 범위 내에서 분할 값을 무작위로 설정
- **무작위 샘플링**: 각 트리 구성 시 데이터에서 샘플을 무작위로 추출


## 중복 이상치 기반 앙상블 방법

### 1. **반복 실행 후 투표 방식**

```python
# 여러 번 실행하여 이상치를 탐지하고 중복되는 것을 찾는 방법
outlier_counts = defaultdict(int)
n_runs = 100

for i in range(n_runs):
    iso_forest = IsolationForest(contamination=0.1, random_state=None)
    predictions = iso_forest.fit_predict(data)
    outliers = np.where(predictions == -1)[^0]
    
    for outlier_idx in outliers:
        outlier_counts[outlier_idx] += 1

# 높은 빈도로 선택된 이상치를 최종 이상치로 결정
threshold = n_runs * 0.5  # 50% 이상 선택된 경우
final_outliers = [idx for idx, count in outlier_counts.items() 
                  if count >= threshold]
```


### 2. **클러스터 기반 개선 방법**

연구에서는 아이솔레이션 포레스트의 불안정성을 해결하기 위해 **클러스터링과 결합한 CIIF(Cluster-based Improved Isolation Forest)** 방법이 제안되었습니다. 이 방법은 k-means 클러스터링을 통해 선택 행렬을 구성하여 무작위성을 제어합니다.[^3]

## 이 방법의 장점

### **안정성 향상**

- 단일 실행에서는 무작위성으로 인해 놓칠 수 있는 진짜 이상치를 더 확실하게 탐지
- **여러 번의 독립적인 실행을 통한 투표 방식**으로 노이즈 감소


### **정확도 개선**

연구 결과에 따르면 클러스터 기반 개선된 아이솔레이션 포레스트는 기존 방법 대비 **평균 AUC 값이 7% 향상**되었습니다.[^3]

### **견고성 확보**

- 특정 실행에서의 편향된 결과를 완화
- **일관성 있는 이상치 탐지** 결과 제공


## 실제 구현 고려사항

### 1. **임계값 설정**

중복 빈도의 임계값은 데이터의 특성과 요구사항에 따라 조정해야 합니다. 일반적으로 50-70% 이상 중복되는 경우를 진짜 이상치로 간주합니다.

### 2. **계산 비용**

반복 실행으로 인한 계산 비용 증가를 고려하여 적절한 반복 횟수(보통 10-100회)를 설정해야 합니다.[^2]

### 3. **contamination 파라미터 조정**

각 실행에서 동일한 contamination 값을 사용하거나, 약간씩 다른 값을 사용하여 더 다양한 관점에서 이상치를 탐지할 수 있습니다.[^1]

따라서 **여러 번 반복하여 중복되는 이상치를 찾는 방법은 아이솔레이션 포레스트의 불안정성을 보완하고 더 정확한 이상치 탐지를 가능하게 하는 효과적인 접근법**입니다.

<div style="text-align: center">⁂</div>

[^1]: https://www.kaggle.com/code/christianlillelund/tutorial-use-isolationforest-to-detect-outliers

[^2]: https://arxiv.org/pdf/2111.11639.pdf

[^3]: https://pmc.ncbi.nlm.nih.gov/articles/PMC9141139/

[^4]: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html

[^5]: https://ardentdays.tistory.com/30

[^6]: https://www.esann.org/sites/default/files/proceedings/2025/ES2025-163.pdf

[^7]: https://www.youtube.com/watch?v=kqAxfOPlr1U

[^8]: https://www.sciencedirect.com/science/article/pii/S0020025521010999

[^9]: https://towardsdatascience.com/outlier-detection-with-isolation-forest-3d190448d45e/

[^10]: https://arxiv.org/pdf/2409.13466.pdf

[^11]: https://towardsdatascience.com/outlier-detection-with-extended-isolation-forest-1e248a3fe97b/

[^12]: https://link.springer.com/article/10.1007/s41060-020-00238-w

[^13]: https://arxiv.org/html/2409.13466v1

[^14]: https://majdarbash.github.io/aws-cmls/2019-11-21-isolation-forest-algorithm/

[^15]: https://www.sciencedirect.com/science/article/abs/pii/S0167865522002847

[^16]: https://dspace.mit.edu/bitstream/handle/1721.1/150844/3588700.pdf?sequence=1\&isAllowed=y

[^17]: https://arxiv.org/html/2403.10802v1

[^18]: https://wikidocs.net/209698

[^19]: https://www.sciencedirect.com/science/article/abs/pii/S0950705122010966

[^20]: https://pmc.ncbi.nlm.nih.gov/articles/PMC10326160/

