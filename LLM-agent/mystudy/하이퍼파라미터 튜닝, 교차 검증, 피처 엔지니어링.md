<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# 하이퍼파라미터 튜닝, 교차 검증, 피처 엔지니어링

데이터 분석 및 머신러닝 모델링의 반복적 분석 과정에서 핵심이 되는 세 가지 기법에 대해 상세히 살펴본다.

## 1. 하이퍼파라미터 튜닝 (Hyperparameter Tuning)

**정의**
모델 학습 전에 사용자가 직접 설정하는 매개변수(하이퍼파라미터)를 최적화하여 모델 성능을 극대화하는 과정.

**주요 기법**

1. 그리드 서치(Grid Search)
    - 미리 정의한 하이퍼파라미터 값들의 모든 조합을 체계적으로 탐색
    - 장점: 탐색 범위가 명확, 구현이 간단
    - 단점: 조합 수가 기하급수적으로 늘어나면 계산 비용 급증
2. 랜덤 서치(Random Search)
    - 하이퍼파라미터 공간에서 무작위로 샘플링하여 탐색
    - 장점: 동일 예산 대비 더 넓은 공간 탐색 가능, 일부 하이퍼파라미터만 중요한 경우 효율적
    - 단점: 최적 해 보장 어려움
3. 베이지안 최적화(Bayesian Optimization)
    - 이전 탐색 결과를 바탕으로 확률 모델을 갱신하며 효율적으로 최적점 탐색
    - 장점: 탐색 비용 절감, 복잡한 공간에서도 우수한 성능
    - 단점: 구현·튜닝이 복잡, 초기 설정 민감

**적용 시 유의사항**

- 검증 데이터 세트를 별도로 유지하여 과적합 방지
- 반복 횟수와 탐색 범위의 균형 고려
- 리소스(시간, 컴퓨팅 파워)에 맞춰 전략 선택

***

## 2. 교차 검증 (Cross-Validation)

**정의**
모델의 일반화 성능을 보다 안정적으로 평가하기 위해 데이터를 여러 개의 폴드(fold)로 나누어 반복 학습·평가하는 기법.

**대표 기법**

1. K-폴드 교차 검증
    - 데이터를 K개의 폴드로 분할한 뒤, K회 반복 동안 매 회 하나의 폴드를 검증 세트로, 나머지를 학습 세트로 사용
    - 평균 성능을 최종 모델 성능으로 채택
2. 반복 K-폴드 교차 검증 (Repeated K-Fold)
    - K-폴드 과정을 여러 번 반복하고 결과를 평균하여 더욱 견고한 평가
3. 계층적(Stratified) 교차 검증
    - 각 폴드가 전체 데이터의 클래스 분포를 유지하도록 샘플링
    - 불균형 데이터셋에서 성능 평가 편향을 줄임

**장점 및 활용**

- 데이터가 적을 때 모델 평가 안정성 확보
- 하이퍼파라미터 튜닝 시 과적합 위험 최소화
- 모델 간 성능 비교에 일관된 평가 지표 제공

***

## 3. 피처 엔지니어링 (Feature Engineering)

**정의**
모델 입력으로 사용되는 특성(피처)의 형태나 값을 변환·생성하여 학습 성능을 개선하는 과정.

**주요 단계**

1. **피처 생성 (Feature Creation)**
    - 도메인 지식을 활용해 새로운 피처를 파생(예: 날짜 → 요일, 주말 여부)
2. **피처 변환 (Feature Transformation)**
    - 스케일링(정규화, 표준화), 로그 변환, 다항식 변환
3. **피처 선택 (Feature Selection)**
    - 상관성 분석, 분산 기반 필터, 래퍼(wrapper) 기법, 임베디드(embedded) 기법으로 유용한 피처만 선별
4. **피처 인코딩 (Feature Encoding)**
    - 범주형 변수 처리: 원-핫 인코딩, 레이블 인코딩, 임베딩
5. **결측치 처리 및 이상치 제거**
    - 평균·중앙값 대체, KNN 임퓨테이션, 이상치 컷오프, 윈저라이징

**효과 및 고려사항**

- 올바른 피처 엔지니어링만으로도 모델 성능이 크게 개선될 수 있음
- 과도한 피처 생성은 과적합 초래 가능
- 자동화 도구(AutoML, FeatureTools) 활용 시, 파생 피처의 품질 검증 필수

***

## 결론

하이퍼파라미터 튜닝, 교차 검증, 피처 엔지니어링은 **반복적 분석(iterative analysis)** 과정의 핵심 축으로, 각 단계에서 얻은 성과를 다음 사이클에 반영하며 모델의 정확도와 일반화 능력을 지속적으로 향상시킨다.

