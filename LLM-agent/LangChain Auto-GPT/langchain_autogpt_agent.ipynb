
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChainì„ ì‚¬ìš©í•œ Auto-GPT ì—ì´ì „íŠ¸ êµ¬í˜„\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” LangChain í”„ë ˆì„ì›Œí¬ë¥¼ ì‚¬ìš©í•˜ì—¬ Auto-GPT ìŠ¤íƒ€ì¼ì˜ ììœ¨ ì—ì´ì „íŠ¸ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì£¼ìš” íŠ¹ì§•:\n",
    "- ììœ¨ì  ëª©í‘œ ì„¤ì • ë° ê³„íš ìˆ˜ë¦½\n",
    "- ì›¹ ê²€ìƒ‰ ë° íŒŒì¼ ê´€ë¦¬ ë„êµ¬ í™œìš©\n",
    "- ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í†µí•œ ì¥ê¸° ë©”ëª¨ë¦¬\n",
    "- ReAct (Reasoning + Acting) íŒ¨í„´ ì ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install langchain-experimental\n",
    "!pip install langchain-openai\n",
    "!pip install langchain-community\n",
    "!pip install faiss-cpu\n",
    "!pip install google-search-results\n",
    "!pip install tiktoken\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ Import\n",
    "import os\n",
    "import faiss\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain Core\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "# LangChain Experimental - AutoGPT\n",
    "from langchain_experimental.autonomous_agents.autogpt.agent import AutoGPT\n",
    "from langchain_experimental.autonomous_agents.autogpt.prompt import AutoGPTPrompt\n",
    "from langchain_experimental.autonomous_agents.autogpt.prompt_generator import get_prompt\n",
    "\n",
    "# LangChain Tools\n",
    "from langchain.agents import Tool\n",
    "from langchain.tools.file_management.write import WriteFileTool\n",
    "from langchain.tools.file_management.read import ReadFileTool\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "# Vector Store and Memory\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# ê¸°íƒ€\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. API í‚¤ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API í‚¤ ì„¤ì •\n",
    "# .env íŒŒì¼ì— ë‹¤ìŒê³¼ ê°™ì´ ì €ì¥í•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥:\n",
    "# OPENAI_API_KEY=your_openai_api_key\n",
    "# SERPAPI_API_KEY=your_serpapi_key\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "serpapi_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "# API í‚¤ê°€ ì—†ëŠ” ê²½ìš° ì§ì ‘ ì…ë ¥\n",
    "if not openai_api_key:\n",
    "    openai_api_key = input(\"OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "if not serpapi_key:\n",
    "    serpapi_key = input(\"SerpAPI í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­, ì›¹ ê²€ìƒ‰ìš©): \")\n",
    "    if serpapi_key:\n",
    "        os.environ[\"SERPAPI_API_KEY\"] = serpapi_key\n",
    "\n",
    "print(\"âœ… API í‚¤ ì„¤ì • ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ë„êµ¬(Tools) ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›¹ ê²€ìƒ‰ ë„êµ¬ ì„¤ì •\n",
    "def setup_search_tool():\n",
    "    \"\"\"ì›¹ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\"\"\"\n",
    "    if serpapi_key:\n",
    "        search = SerpAPIWrapper(serpapi_api_key=serpapi_key)\n",
    "        return Tool(\n",
    "            name=\"search\",\n",
    "            func=search.run,\n",
    "            description=\"ìµœì‹  ì •ë³´ë‚˜ ì‹¤ì‹œê°„ ì •ë³´ê°€ í•„ìš”í•  ë•Œ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì •í™•í•œ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•˜ì„¸ìš”.\"\n",
    "        )\n",
    "    else:\n",
    "        # SerpAPI í‚¤ê°€ ì—†ëŠ” ê²½ìš° ë”ë¯¸ ê²€ìƒ‰ í•¨ìˆ˜\n",
    "        def dummy_search(query: str) -> str:\n",
    "            return f\"ê²€ìƒ‰ ê²°ê³¼: {query}ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. SerpAPI í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
    "        \n",
    "        return Tool(\n",
    "            name=\"search\",\n",
    "            func=dummy_search,\n",
    "            description=\"ì›¹ ê²€ìƒ‰ ë„êµ¬ (SerpAPI í‚¤ í•„ìš”)\"\n",
    "        )\n",
    "\n",
    "# ê³„ì‚°ê¸° ë„êµ¬\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"ê°„ë‹¨í•œ ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        # ì•ˆì „í•œ ê³„ì‚°ì„ ìœ„í•´ eval ëŒ€ì‹  ì œí•œëœ ì—°ì‚°ë§Œ í—ˆìš©\n",
    "        allowed_chars = set('0123456789+-*/(). ')\n",
    "        if all(c in allowed_chars for c in expression):\n",
    "            result = eval(expression)\n",
    "            return f\"ê³„ì‚° ê²°ê³¼: {expression} = {result}\"\n",
    "        else:\n",
    "            return \"ì˜ëª»ëœ ìˆ˜ì‹ì…ë‹ˆë‹¤. ìˆ«ìì™€ ê¸°ë³¸ ì—°ì‚°ìë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\"\n",
    "    except Exception as e:\n",
    "        return f\"ê³„ì‚° ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "# í˜„ì¬ ì‹œê°„ í™•ì¸ ë„êµ¬\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"í˜„ì¬ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return f\"í˜„ì¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "# ë„êµ¬ë“¤ ì„¤ì •\n",
    "search_tool = setup_search_tool()\n",
    "write_file_tool = WriteFileTool()\n",
    "read_file_tool = ReadFileTool()\n",
    "\n",
    "calculator_tool = Tool(\n",
    "    name=\"calculator\",\n",
    "    func=calculator,\n",
    "    description=\"ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì˜ˆ: '2+2' ë˜ëŠ” '10*5-3'\"\n",
    ")\n",
    "\n",
    "time_tool = Tool(\n",
    "    name=\"current_time\",\n",
    "    func=get_current_time,\n",
    "    description=\"í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ í™•ì¸í•©ë‹ˆë‹¤.\"\n",
    ")\n",
    "\n",
    "# ëª¨ë“  ë„êµ¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ë¦¬\n",
    "tools = [\n",
    "    search_tool,\n",
    "    write_file_tool,\n",
    "    read_file_tool,\n",
    "    calculator_tool,\n",
    "    time_tool\n",
    "]\n",
    "\n",
    "print(f\"âœ… ì´ {len(tools)}ê°œì˜ ë„êµ¬ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤:\")\n",
    "for tool in tools:\n",
    "    print(f\"  - {tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë²¡í„° ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ë² ë”© ëª¨ë¸ê³¼ ë²¡í„° ìŠ¤í† ì–´ ì„¤ì •\n",
    "def setup_memory_system():\n",
    "    \"\"\"FAISSë¥¼ ì‚¬ìš©í•œ ë²¡í„° ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ ì„¤ì •í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    # OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "    embeddings_model = OpenAIEmbeddings(\n",
    "        openai_api_key=openai_api_key,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    \n",
    "    # ì„ë² ë”© ì°¨ì› (OpenAI text-embedding-3-smallì˜ ê²½ìš° 1536)\n",
    "    embedding_size = 1536\n",
    "    \n",
    "    # FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™” (L2 ê±°ë¦¬ ì‚¬ìš©)\n",
    "    index = faiss.IndexFlatL2(embedding_size)\n",
    "    \n",
    "    # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±\n",
    "    vectorstore = FAISS(\n",
    "        embedding_function=embeddings_model.embed_query,\n",
    "        index=index,\n",
    "        docstore=InMemoryDocstore({}),\n",
    "        index_to_docstore_id={}\n",
    "    )\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì„¤ì •\n",
    "vectorstore = setup_memory_system()\n",
    "print(\"âœ… ë²¡í„° ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LLM ëª¨ë¸ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOpenAI ëª¨ë¸ ì„¤ì •\n",
    "def setup_llm(model_name=\"gpt-4o-mini\", temperature=0.1):\n",
    "    \"\"\"OpenAI ì–¸ì–´ ëª¨ë¸ì„ ì„¤ì •í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key=openai_api_key,\n",
    "        model_name=model_name,\n",
    "        temperature=temperature,\n",
    "        max_tokens=2000\n",
    "    )\n",
    "    \n",
    "    return llm\n",
    "\n",
    "# LLM ëª¨ë¸ ì´ˆê¸°í™”\n",
    "llm = setup_llm()\n",
    "print(f\"âœ… {llm.model_name} ëª¨ë¸ì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Auto-GPT ì—ì´ì „íŠ¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-GPT ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ ì •ì˜\n",
    "class AutoGPTAgent:\n",
    "    def __init__(self, ai_name: str, ai_role: str, llm, tools, vectorstore):\n",
    "        self.ai_name = ai_name\n",
    "        self.ai_role = ai_role\n",
    "        self.llm = llm\n",
    "        self.tools = tools\n",
    "        self.vectorstore = vectorstore\n",
    "        \n",
    "        # AutoGPT ì—ì´ì „íŠ¸ ìƒì„±\n",
    "        self.agent = AutoGPT.from_llm_and_tools(\n",
    "            ai_name=self.ai_name,\n",
    "            ai_role=self.ai_role,\n",
    "            tools=self.tools,\n",
    "            llm=self.llm,\n",
    "            memory=self.vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "        )\n",
    "    \n",
    "    def run(self, goals: List[str], max_iterations: int = 10) -> str:\n",
    "        \"\"\"ì£¼ì–´ì§„ ëª©í‘œë“¤ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "        print(f\"ğŸ¤– {self.ai_name} ì—ì´ì „íŠ¸ê°€ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "        print(f\"ğŸ“‹ ëª©í‘œ: {goals}\")\n",
    "        print(f\"ğŸ”„ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜: {max_iterations}\")\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        \n",
    "        try:\n",
    "            result = self.agent.run(goals)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            error_msg = f\"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
    "            print(f\"âŒ {error_msg}\")\n",
    "            return error_msg\n",
    "    \n",
    "    def add_memory(self, text: str):\n",
    "        \"\"\"ë©”ëª¨ë¦¬ì— í…ìŠ¤íŠ¸ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\"\"\"\n",
    "        from langchain.docstore.document import Document\n",
    "        doc = Document(page_content=text)\n",
    "        self.vectorstore.add_documents([doc])\n",
    "        print(f\"ğŸ’¾ ë©”ëª¨ë¦¬ì— ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {text[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-GPT ì—ì´ì „íŠ¸ ìƒì„±\n",
    "def create_autogpt_agent(ai_name: str = \"ResearchGPT\", \n",
    "                        ai_role: str = \"ì—°êµ¬ ë° ë¶„ì„ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸\"):\n",
    "    \"\"\"Auto-GPT ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    agent = AutoGPTAgent(\n",
    "        ai_name=ai_name,\n",
    "        ai_role=ai_role,\n",
    "        llm=llm,\n",
    "        tools=tools,\n",
    "        vectorstore=vectorstore\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "autogpt_agent = create_autogpt_agent()\n",
    "\n",
    "print(f\"âœ… {autogpt_agent.ai_name} ì—ì´ì „íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"ğŸ¯ ì—­í• : {autogpt_agent.ai_role}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì‚¬ìš© ì˜ˆì œ 1: ê°„ë‹¨í•œ ì—°êµ¬ ì‘ì—…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì œ 1: ê°„ë‹¨í•œ ì—°êµ¬ ë° íŒŒì¼ ìƒì„± ì‘ì—…\n",
    "def example_1_research_task():\n",
    "    \"\"\"ê°„ë‹¨í•œ ì—°êµ¬ ì‘ì—… ì˜ˆì œ\"\"\"\n",
    "    \n",
    "    goals = [\n",
    "        \"Pythonì˜ ì£¼ìš” íŠ¹ì§•ì— ëŒ€í•´ ì¡°ì‚¬í•˜ê³  ì •ë¦¬í•˜ê¸°\",\n",
    "        \"ì¡°ì‚¬í•œ ë‚´ìš©ì„ 'python_features.txt' íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°\",\n",
    "        \"íŒŒì¼ì´ ì œëŒ€ë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê¸°\"\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ“ ì˜ˆì œ 1: Python íŠ¹ì§• ì—°êµ¬ ì‘ì—…\")\n",
    "    result = autogpt_agent.run(goals, max_iterations=15)\n",
    "    \n",
    "    print(\"\\nğŸ ì‘ì—… ì™„ë£Œ!\")\n",
    "    print(f\"ê²°ê³¼: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ì˜ˆì œ ì‹¤í–‰\n",
    "result_1 = example_1_research_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ì‚¬ìš© ì˜ˆì œ 2: ê³„ì‚°ê³¼ ë¶„ì„ ì‘ì—…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì œ 2: ê³„ì‚°ê³¼ ë¶„ì„ ì‘ì—…\n",
    "def example_2_calculation_task():\n",
    "    \"\"\"ê³„ì‚°ê³¼ ë¶„ì„ ì‘ì—… ì˜ˆì œ\"\"\"\n",
    "    \n",
    "    goals = [\n",
    "        \"í˜„ì¬ ì‹œê°„ì„ í™•ì¸í•˜ê¸°\",\n",
    "        \"1ë¶€í„° 100ê¹Œì§€ì˜ í•©ì„ ê³„ì‚°í•˜ê¸°\",\n",
    "        \"ê³„ì‚° ê²°ê³¼ì™€ í˜„ì¬ ì‹œê°„ì„ í¬í•¨í•œ ë³´ê³ ì„œë¥¼ 'calculation_report.txt' íŒŒì¼ë¡œ ì‘ì„±í•˜ê¸°\"\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ”¢ ì˜ˆì œ 2: ê³„ì‚° ë° ë³´ê³ ì„œ ì‘ì„± ì‘ì—…\")\n",
    "    result = autogpt_agent.run(goals, max_iterations=10)\n",
    "    \n",
    "    print(\"\\nğŸ ì‘ì—… ì™„ë£Œ!\")\n",
    "    print(f\"ê²°ê³¼: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ì˜ˆì œ ì‹¤í–‰\n",
    "result_2 = example_2_calculation_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ì‚¬ìš© ì˜ˆì œ 3: ë³µí•© ì‘ì—… (ê²€ìƒ‰ + ë¶„ì„ + ì €ì¥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì œ 3: ë³µí•© ì‘ì—… - ê²€ìƒ‰, ë¶„ì„, ì €ì¥\n",
    "def example_3_complex_task():\n",
    "    \"\"\"ë³µí•© ì‘ì—… ì˜ˆì œ: ì •ë³´ ê²€ìƒ‰, ë¶„ì„, íŒŒì¼ ì €ì¥\"\"\"\n",
    "    \n",
    "    goals = [\n",
    "        \"ì¸ê³µì§€ëŠ¥ì˜ ìµœì‹  ë™í–¥ì— ëŒ€í•´ ì¡°ì‚¬í•˜ê¸°\",\n",
    "        \"ì¡°ì‚¬í•œ ì •ë³´ë¥¼ ìš”ì•½í•˜ê³  ë¶„ì„í•˜ê¸°\",\n",
    "        \"ë¶„ì„ ê²°ê³¼ë¥¼ 'ai_trends_analysis.txt' íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°\",\n",
    "        \"ì €ì¥ëœ íŒŒì¼ì˜ ë‚´ìš©ì„ í™•ì¸í•˜ì—¬ ì˜¬ë°”ë¥´ê²Œ ì €ì¥ë˜ì—ˆëŠ”ì§€ ê²€ì¦í•˜ê¸°\"\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ” ì˜ˆì œ 3: AI ë™í–¥ ì¡°ì‚¬ ë° ë¶„ì„ ì‘ì—…\")\n",
    "    result = autogpt_agent.run(goals, max_iterations=20)\n",
    "    \n",
    "    print(\"\\nğŸ ì‘ì—… ì™„ë£Œ!\")\n",
    "    print(f\"ê²°ê³¼: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ì˜ˆì œ ì‹¤í–‰\n",
    "result_3 = example_3_complex_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ì‚¬ìš©ì ì •ì˜ ì‘ì—… ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ìê°€ ì§ì ‘ ëª©í‘œë¥¼ ì„¤ì •í•˜ì—¬ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜\n",
    "def run_custom_task():\n",
    "    \"\"\"ì‚¬ìš©ì ì •ì˜ ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    print(\"ğŸ¯ ì‚¬ìš©ì ì •ì˜ ì‘ì—…ì„ ì„¤ì •í•˜ì„¸ìš”.\")\n",
    "    print(\"ì—¬ëŸ¬ ê°œì˜ ëª©í‘œë¥¼ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° ëª©í‘œë¥¼ í•œ ì¤„ì”© ì…ë ¥í•˜ê³ , ì™„ë£Œí•˜ë©´ ë¹ˆ ì¤„ì„ ì…ë ¥í•˜ì„¸ìš”.\\n\")\n",
    "    \n",
    "    goals = []\n",
    "    goal_num = 1\n",
    "    \n",
    "    while True:\n",
    "        goal = input(f\"ëª©í‘œ {goal_num}: \").strip()\n",
    "        if not goal:\n",
    "            break\n",
    "        goals.append(goal)\n",
    "        goal_num += 1\n",
    "    \n",
    "    if not goals:\n",
    "        print(\"âŒ ëª©í‘œê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ì„¤ì •\n",
    "    max_iterations = int(input(\"ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸ê°’: 15): \") or 15)\n",
    "    \n",
    "    print(f\"\\nğŸš€ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    result = autogpt_agent.run(goals, max_iterations=max_iterations)\n",
    "    \n",
    "    print(\"\\nğŸ ì‚¬ìš©ì ì •ì˜ ì‘ì—… ì™„ë£Œ!\")\n",
    "    print(f\"ê²°ê³¼: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ì‚¬ìš©ì ì •ì˜ ì‘ì—… ì‹¤í–‰ (ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰)\n",
    "# custom_result = run_custom_task()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. ê³ ê¸‰ ê¸°ëŠ¥: ë©”ëª¨ë¦¬ ê´€ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”ëª¨ë¦¬ ê´€ë¦¬ ê¸°ëŠ¥\n",
    "def manage_memory():\n",
    "    \"\"\"ì—ì´ì „íŠ¸ì˜ ë©”ëª¨ë¦¬ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    print(\"ğŸ§  ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ\")\n",
    "    print(\"1. ë©”ëª¨ë¦¬ì— ì •ë³´ ì¶”ê°€\")\n",
    "    print(\"2. ë©”ëª¨ë¦¬ ê²€ìƒ‰\")\n",
    "    print(\"3. ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\")\n",
    "    \n",
    "    choice = input(\"ì„ íƒí•˜ì„¸ìš” (1-3): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        info = input(\"ë©”ëª¨ë¦¬ì— ì¶”ê°€í•  ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "        autogpt_agent.add_memory(info)\n",
    "        \n",
    "    elif choice == \"2\":\n",
    "        query = input(\"ê²€ìƒ‰í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "        retriever = autogpt_agent.vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "        docs = retriever.get_relevant_documents(query)\n",
    "        \n",
    "        print(f\"\\nğŸ” '{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "        for i, doc in enumerate(docs, 1):\n",
    "            print(f\"{i}. {doc.page_content[:200]}...\")\n",
    "            \n",
    "    elif choice == \"3\":\n",
    "        # ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸\n",
    "        total_docs = len(autogpt_agent.vectorstore.docstore._dict)\n",
    "        print(f\"ğŸ’¾ í˜„ì¬ ë©”ëª¨ë¦¬ì— ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {total_docs}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.\")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹¤í–‰ (ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰)\n",
    "# manage_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    def __init__(self):\n",
    "        self.execution_logs = []\n",
    "        self.start_time = None\n",
    "        self.end_time = None\n",
    "    \n",
    "    def start_monitoring(self, task_name: str):\n",
    "        self.start_time = time.time()\n",
    "        print(f\"â±ï¸  '{task_name}' ëª¨ë‹ˆí„°ë§ ì‹œì‘: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    def end_monitoring(self, task_name: str):\n",
    "        self.end_time = time.time()\n",
    "        duration = self.end_time - self.start_time\n",
    "        \n",
    "        log_entry = {\n",
    "            \"task\": task_name,\n",
    "            \"start_time\": self.start_time,\n",
    "            \"end_time\": self.end_time,\n",
    "            \"duration\": duration,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        self.execution_logs.append(log_entry)\n",
    "        print(f\"â±ï¸  '{task_name}' ì™„ë£Œ: {duration:.2f}ì´ˆ ì†Œìš”\")\n",
    "        \n",
    "    def get_performance_report(self):\n",
    "        if not self.execution_logs:\n",
    "            return \"ìˆ˜í–‰ëœ ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        report = \"\\nğŸ“Š ì„±ëŠ¥ ë³´ê³ ì„œ\\n\" + \"=\"*30 + \"\\n\"\n",
    "        total_time = sum(log[\"duration\"] for log in self.execution_logs)\n",
    "        avg_time = total_time / len(self.execution_logs)\n",
    "        \n",
    "        report += f\"ì´ ì‘ì—… ìˆ˜: {len(self.execution_logs)}\\n\"\n",
    "        report += f\"ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.2f}ì´ˆ\\n\"\n",
    "        report += f\"í‰ê·  ì‹¤í–‰ ì‹œê°„: {avg_time:.2f}ì´ˆ\\n\\n\"\n",
    "        \n",
    "        report += \"ì‘ì—…ë³„ ì‹¤í–‰ ì‹œê°„:\\n\"\n",
    "        for i, log in enumerate(self.execution_logs, 1):\n",
    "            report += f\"{i}. {log['task']}: {log['duration']:.2f}ì´ˆ\\n\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "# ì„±ëŠ¥ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "performance_monitor = PerformanceMonitor()\n",
    "\n",
    "# ëª¨ë‹ˆí„°ë§ì´ í¬í•¨ëœ ì‘ì—… ì‹¤í–‰ í•¨ìˆ˜\n",
    "def run_monitored_task(goals: List[str], task_name: str = \"Custom Task\"):\n",
    "    \"\"\"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ê³¼ í•¨ê»˜ ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    performance_monitor.start_monitoring(task_name)\n",
    "    \n",
    "    try:\n",
    "        result = autogpt_agent.run(goals, max_iterations=15)\n",
    "        performance_monitor.end_monitoring(task_name)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        performance_monitor.end_monitoring(task_name)\n",
    "        print(f\"âŒ ì‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# ì„±ëŠ¥ ë³´ê³ ì„œ ì¶œë ¥\n",
    "def show_performance_report():\n",
    "    print(performance_monitor.get_performance_report())\n",
    "\n",
    "print(\"âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸\n",
    "def comprehensive_test():\n",
    "    \"\"\"Auto-GPT ì‹œìŠ¤í…œì˜ ì¢…í•©ì ì¸ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    print(\"ğŸ§ª Auto-GPT ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"ê¸°ë³¸ íŒŒì¼ ì¡°ì‘\",\n",
    "            \"goals\": [\n",
    "                \"í˜„ì¬ ì‹œê°„ì„ í™•ì¸í•˜ê¸°\",\n",
    "                \"ì‹œê°„ ì •ë³´ë¥¼ 'current_time.txt' íŒŒì¼ì— ì €ì¥í•˜ê¸°\",\n",
    "                \"ì €ì¥ëœ íŒŒì¼ì„ ì½ì–´ì„œ ë‚´ìš© í™•ì¸í•˜ê¸°\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ê³„ì‚° ë° ë¶„ì„\",\n",
    "            \"goals\": [\n",
    "                \"10 + 20 * 3ì„ ê³„ì‚°í•˜ê¸°\",\n",
    "                \"ê³„ì‚° ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì„¤ëª…í•˜ê¸°\",\n",
    "                \"ê²°ê³¼ë¥¼ 'calculation_analysis.txt' íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for test_case in test_cases:\n",
    "        print(f\"\\nğŸ”§ í…ŒìŠ¤íŠ¸: {test_case['name']}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        try:\n",
    "            result = run_monitored_task(test_case[\"goals\"], test_case[\"name\"])\n",
    "            results[test_case[\"name\"]] = {\"success\": True, \"result\": result}\n",
    "            print(f\"âœ… {test_case['name']} í…ŒìŠ¤íŠ¸ ì„±ê³µ\")\n",
    "        except Exception as e:\n",
    "            results[test_case[\"name\"]] = {\"success\": False, \"error\": str(e)}\n",
    "            print(f\"âŒ {test_case['name']} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\n",
    "    print(\"\\nğŸ“‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    success_count = sum(1 for r in results.values() if r[\"success\"])\n",
    "    total_count = len(results)\n",
    "    \n",
    "    print(f\"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {total_count}\")\n",
    "    print(f\"ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {success_count}\")\n",
    "    print(f\"ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸: {total_count - success_count}\")\n",
    "    print(f\"ì„±ê³µë¥ : {(success_count/total_count)*100:.1f}%\")\n",
    "    \n",
    "    # ì„±ëŠ¥ ë³´ê³ ì„œ ì¶œë ¥\n",
    "    show_performance_report()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "test_results = comprehensive_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. ì‹œìŠ¤í…œ ì •ë³´ ë° ë„ì›€ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œìŠ¤í…œ ì •ë³´ ë° ë„ì›€ë§ í•¨ìˆ˜\n",
    "def show_system_info():\n",
    "    \"\"\"ì‹œìŠ¤í…œ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    print(\"ğŸ¤– Auto-GPT ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì •ë³´\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"ì—ì´ì „íŠ¸ ì´ë¦„: {autogpt_agent.ai_name}\")\n",
    "    print(f\"ì—ì´ì „íŠ¸ ì—­í• : {autogpt_agent.ai_role}\")\n",
    "    print(f\"ì‚¬ìš© ì¤‘ì¸ LLM: {autogpt_agent.llm.model_name}\")\n",
    "    print(f\"ë“±ë¡ëœ ë„êµ¬ ìˆ˜: {len(autogpt_agent.tools)}\")\n",
    "    \n",
    "    print(\"\\nğŸ› ï¸  ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:\")\n",
    "    for i, tool in enumerate(autogpt_agent.tools, 1):\n",
    "        print(f\"{i}. {tool.name}: {tool.description}\")\n",
    "    \n",
    "    print(\"\\nğŸ’¾ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ:\")\n",
    "    total_docs = len(autogpt_agent.vectorstore.docstore._dict)\n",
    "    print(f\"ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {total_docs}\")\n",
    "    print(\"ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤: FAISS\")\n",
    "    print(\"ì„ë² ë”© ëª¨ë¸: OpenAI text-embedding-3-small\")\n",
    "\n",
    "def show_usage_guide():\n",
    "    \"\"\"ì‚¬ìš© ê°€ì´ë“œë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“– Auto-GPT ì—ì´ì „íŠ¸ ì‚¬ìš© ê°€ì´ë“œ\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"1. ê¸°ë³¸ ì‚¬ìš©ë²•:\")\n",
    "    print(\"   - ëª©í‘œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤\")\n",
    "    print(\"   - autogpt_agent.run(goals)ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤\")\n",
    "    \n",
    "    print(\"2. ëª©í‘œ ì‘ì„± íŒ:\")\n",
    "    print(\"   - êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ëª©í‘œë¥¼ ì„¤ì •í•˜ì„¸ìš”\")\n",
    "    print(\"   - ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ ì‘ì„±í•˜ì„¸ìš”\")\n",
    "    print(\"   - ê²€ì¦ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì„¸ìš”\")\n",
    "    \n",
    "    print(\"3. ì˜ˆì œ ëª©í‘œë“¤:\")\n",
    "    print(\"   - 'íŠ¹ì • ì£¼ì œì— ëŒ€í•´ ì¡°ì‚¬í•˜ê³  ë³´ê³ ì„œ ì‘ì„±í•˜ê¸°'\")\n",
    "    print(\"   - 'ê³„ì‚°ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°'\")\n",
    "    print(\"   - 'ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìš”ì•½í•˜ê¸°'\")\n",
    "    \n",
    "    print(\"4. ì£¼ì˜ì‚¬í•­:\")\n",
    "    print(\"   - API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”\")\n",
    "    print(\"   - ë³µì¡í•œ ì‘ì—…ì˜ ê²½ìš° ì¶©ë¶„í•œ ë°˜ë³µ íšŸìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”\")\n",
    "    print(\"   - íŒŒì¼ ì‘ì—… ì‹œ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”\")\n",
    "\n",
    "# ì‹œìŠ¤í…œ ì •ë³´ ë° ê°€ì´ë“œ ì¶œë ¥\n",
    "show_system_info()\n",
    "print(\"\\n\")\n",
    "show_usage_guide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. ë§ˆë¬´ë¦¬ ë° ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì •ë¦¬ í•¨ìˆ˜\n",
    "def cleanup_and_summary():\n",
    "    \"\"\"ìƒì„±ëœ íŒŒì¼ë“¤ì„ ì •ë¦¬í•˜ê³  ìš”ì•½ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\"\"\"\n",
    "    \n",
    "    import os\n",
    "    import glob\n",
    "    \n",
    "    print(\"ğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ë° ìš”ì•½\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ìƒì„±ëœ íŒŒì¼ë“¤ í™•ì¸\n",
    "    txt_files = glob.glob(\"*.txt\")\n",
    "    if txt_files:\n",
    "        print(f\"ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤ ({len(txt_files)}ê°œ):\")\n",
    "        for file in txt_files:\n",
    "            size = os.path.getsize(file)\n",
    "            print(f\"  - {file} ({size} bytes)\")\n",
    "    else:\n",
    "        print(\"ğŸ“ ìƒì„±ëœ í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ìƒíƒœ\n",
    "    total_docs = len(autogpt_agent.vectorstore.docstore._dict)\n",
    "    print(f\"\\nğŸ’¾ ë©”ëª¨ë¦¬ ìƒíƒœ: {total_docs}ê°œì˜ ë¬¸ì„œê°€ ì €ì¥ë¨\")\n",
    "    \n",
    "    # ì„±ëŠ¥ ìš”ì•½\n",
    "    if performance_monitor.execution_logs:\n",
    "        print(f\"\\nâ±ï¸  ì´ {len(performance_monitor.execution_logs)}ê°œì˜ ì‘ì—…ì´ ì‹¤í–‰ë¨\")\n",
    "        total_time = sum(log[\"duration\"] for log in performance_monitor.execution_logs)\n",
    "        print(f\"ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.2f}ì´ˆ\")\n",
    "    \n",
    "    print(\"\\nâœ… Auto-GPT ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„ë˜ê³  í…ŒìŠ¤íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    print(\"\\nğŸ’¡ ì¶”ê°€ ê°œë°œ ì•„ì´ë””ì–´:\")\n",
    "    print(\"  - ë” ë‹¤ì–‘í•œ ë„êµ¬ ì¶”ê°€ (ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°, API í˜¸ì¶œ ë“±)\")\n",
    "    print(\"  - GUI ì¸í„°í˜ì´ìŠ¤ ê°œë°œ\")\n",
    "    print(\"  - ì‘ì—… ìŠ¤ì¼€ì¤„ë§ ê¸°ëŠ¥ ì¶”ê°€\")\n",
    "    print(\"  - ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í˜‘ì—… ì‹œìŠ¤í…œ êµ¬ì¶•\")\n",
    "\n",
    "# ìµœì¢… ì •ë¦¬\n",
    "cleanup_and_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
